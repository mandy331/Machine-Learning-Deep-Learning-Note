{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取BBC. UDN. HK01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk = pd.read_csv(\"Data_class/香港01.csv\")\n",
    "udn = pd.read_csv(\"Data_class/UDN.csv\")\n",
    "bbc = pd.read_csv(\"Data_class/BBC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 15:20:47\n",
      "2019-11-30\n",
      "2019-03-31\n"
     ]
    }
   ],
   "source": [
    "print(bbc[\"日期\"][0])\n",
    "print(udn[\"日期\"][0])\n",
    "print(hk[\"日期\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date1(each_row):\n",
    "    b = datetime.datetime.strptime(each_row, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return b\n",
    "def to_date2(each_row):\n",
    "    c = datetime.datetime.strptime(each_row, \"%Y-%m-%d\")\n",
    "    return c\n",
    "\n",
    "bbc[\"日期\"] = bbc[\"日期\"].apply(to_date1, 1)\n",
    "udn[\"日期\"] = udn[\"日期\"].apply(to_date2, 1)\n",
    "hk[\"日期\"] = hk[\"日期\"].apply(to_date2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba斷詞(有自建辭典)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/9t/t_r18jtx2t17njq7cpc2q1d80000gn/T/jieba.cache\n",
      "Loading model cost 1.064 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict(\"dict2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a036c0f450834d939437c179e6ac1b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1570), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d888afe04cc4ba596f16f5edabe2c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb432252c0b4c218edfd89c300a7cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=376), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def parsing_jieba(row):\n",
    "    stop_list = [line[:-1] for line in open(\"stop_words.txt\")]\n",
    "    sentence = \"\"\n",
    "    words = []\n",
    "    for k in jieba.cut(row, cut_all = False):\n",
    "        if k not in stop_list and k  != ' ':\n",
    "            sentence = sentence + \" \" + k\n",
    "            words.append(k)\n",
    "    return sentence, words\n",
    "jieba_segment1, jieba_segment2 = [], []\n",
    "for i in tqdm_notebook(range(len(hk))):\n",
    "    s, w = parsing_jieba(hk[\"內容\"][i])\n",
    "    jieba_segment1.append(s)\n",
    "    jieba_segment2.append(w)\n",
    "jieba_segment3, jieba_segment4 = [], []\n",
    "for i in tqdm_notebook(range(len(udn))):\n",
    "    s, w = parsing_jieba(udn[\"內容\"][i])\n",
    "    jieba_segment3.append(s)\n",
    "    jieba_segment4.append(w)\n",
    "jieba_segment5, jieba_segment6 = [], []\n",
    "for i in tqdm_notebook(range(len(bbc))):\n",
    "    s, w = parsing_jieba(bbc[\"內容\"][i])\n",
    "    jieba_segment5.append(s)\n",
    "    jieba_segment6.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk['jieba_sentence'], hk['jieba_list'] = jieba_segment1, jieba_segment2\n",
    "udn['jieba_sentence'], udn['jieba_list'] = jieba_segment3, jieba_segment4\n",
    "bbc['jieba_sentence'], bbc['jieba_list'] = jieba_segment5, jieba_segment6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df):\n",
    "    train = df[df['立場'].isna() != True].reset_index(drop=True)\n",
    "    test = df[df['立場'].isna() == True].reset_index(drop=True)\n",
    "    return train, test\n",
    "hk_train, hk_test = train_test(hk)\n",
    "udn_train, udn_test = train_test(udn)\n",
    "bbc_train, bbc_test = train_test(bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "hk_train['新聞媒體'] = \"香港01\"\n",
    "udn_train['新聞媒體'] = \"UDN\"\n",
    "bbc_train['新聞媒體'] = \"BBC中文\"\n",
    "all_train =  pd.concat([hk_train, udn_train, bbc_train], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>jieba_list</th>\n",
       "      <th>jieba_sentence</th>\n",
       "      <th>內容</th>\n",
       "      <th>搜尋</th>\n",
       "      <th>日期</th>\n",
       "      <th>標籤</th>\n",
       "      <th>標題</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>新聞媒體</th>\n",
       "      <th>立場</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">BBC中文</th>\n",
       "      <th>0.0</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">UDN</th>\n",
       "      <th>0.0</th>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">香港01</th>\n",
       "      <th>0.0</th>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Url  jieba_list  jieba_sentence   內容   搜尋   日期   標籤   標題\n",
       "新聞媒體  立場                                                           \n",
       "BBC中文 0.0   42          42              42   42   42   42   42   42\n",
       "      1.0  117         117             117  117  117  117  117  117\n",
       "      2.0   78          78              78   78   78   78   78   78\n",
       "UDN   0.0  480         480             480  480  480  480  480  480\n",
       "      1.0  596         596             596  596  596  596  596  596\n",
       "      2.0  683         683             683  683  683  683  683  683\n",
       "香港01  0.0  193         193             193  193  193  193  193  193\n",
       "      1.0  405         405             405  405  405  405  405  405\n",
       "      2.0  235         235             235  235  235  235  235  235"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.groupby([\"新聞媒體\",\"立場\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame([['反對','香港01',193],['中立','香港01',405],['支持','香港01',235],['反對','UDN',480],\n",
    "                   ['中立','UDN',596],['支持','UDN',683], ['反對','BBC中文',42],\n",
    "                   ['中立','BBC中文',117],['支持','BBC中文',78]],columns=['立場','新聞媒體','個數'])\n",
    "\n",
    "fig = df.pivot(\"新聞媒體\", \"立場\", \"個數\").plot(kind='bar')\n",
    "fig.figure.savefig(\"all.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "MAX_NUM_WORDS = 10000\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2829,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_hk = hk_train['jieba_sentence']\n",
    "corpus_udn = udn_train['jieba_sentence']\n",
    "corpus_bbc = bbc_train['jieba_sentence']\n",
    "corpus = pd.concat([corpus_hk, corpus_udn, corpus_bbc], axis = 0)\n",
    "corpus = corpus.reset_index(drop = True)\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_train_corpus = tokenizer.texts_to_sequences(corpus_hk)\n",
    "udn_train_corpus = tokenizer.texts_to_sequences(corpus_udn)\n",
    "bbc_train_corpus = tokenizer.texts_to_sequences(corpus_bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將Token轉成一樣長的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "1243\n",
      "1544\n"
     ]
    }
   ],
   "source": [
    "hk_max_seq_len = max([len(seq) for seq in hk_train_corpus])\n",
    "udn_max_seq_len = max([len(seq) for seq in udn_train_corpus])\n",
    "bbc_max_seq_len = max([len(seq) for seq in bbc_train_corpus])\n",
    "print(hk_max_seq_len)\n",
    "print(udn_max_seq_len)\n",
    "print(bbc_max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "hk_train_corpus = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(hk_train_corpus, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "udn_train_corpus = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(udn_train_corpus, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "bbc_train_corpus = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(bbc_train_corpus, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3089\n",
      "1028\n",
      "1947\n"
     ]
    }
   ],
   "source": [
    "corpus_hk_test = hk_test['jieba_sentence']\n",
    "corpus_udn_test = udn_test['jieba_sentence']\n",
    "corpus_bbc_test = bbc_test['jieba_sentence']\n",
    "corpus_test = pd.concat([corpus_hk_test, corpus_udn_test, corpus_bbc_test], axis = 0)\n",
    "corpus_test = corpus_test.reset_index(drop = True)\n",
    "corpus_test.shape\n",
    "tokenizer.fit_on_texts(corpus_test)\n",
    "hk_test_corpus = tokenizer.texts_to_sequences(corpus_hk_test)\n",
    "udn_test_corpus = tokenizer.texts_to_sequences(corpus_udn_test)\n",
    "bbc_test_corpus = tokenizer.texts_to_sequences(corpus_bbc_test)\n",
    "hk_max_seq_test_len = max([len(seq) for seq in hk_test_corpus])\n",
    "udn_max_seq_test_len = max([len(seq) for seq in udn_test_corpus])\n",
    "bbc_max_seq_test_len = max([len(seq) for seq in bbc_test_corpus])\n",
    "print(hk_max_seq_test_len)\n",
    "print(udn_max_seq_test_len)\n",
    "print(bbc_max_seq_test_len)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "hk_test_corpus = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(hk_test_corpus, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "udn_test_corpus = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(udn_test_corpus, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "bbc_test_corpus = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(bbc_test_corpus, \n",
    "                   maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch_立場預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def binary_accuracy(preds, y):\n",
    "    correct = (preds.argmax(dim=1) == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_y_test = torch.LongTensor(hk_test_corpus).to(device)\n",
    "udn_y_test = torch.LongTensor(udn_test_corpus).to(device)\n",
    "bbc_y_test = torch.LongTensor(bbc_test_corpus).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HK01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_train_y = np.asarray(hk_train['立場']).astype(int)\n",
    "HK_x_train, HK_x_val, HK_y_train, HK_y_val = train_test_split(hk_train_corpus,  hk_train_y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "sentence_max_lenght = 200\n",
    "embedding_size = 150\n",
    "output_size = 30\n",
    "epochs = 150\n",
    "batch_size = 3000\n",
    "H1 = 130\n",
    "H2 = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = torch.LongTensor(HK_x_train).to(device), torch.LongTensor(HK_y_train).to(device)\n",
    "x_test, y_test = torch.LongTensor(HK_x_val).to(device), torch.LongTensor(HK_y_val).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEWS_NET2(torch.nn.Module):\n",
    "    def __init__(self, vocab_size,\n",
    "                 embedding_size,\n",
    "                 output_size,\n",
    "                 H1,\n",
    "                 H2):\n",
    "        super(NEWS_NET2, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size , embedding_size)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_size, H1, bias=False),\n",
    "            torch.nn.Dropout(0.1),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H1, H2, bias=False),\n",
    "            torch.nn.Dropout(0.1), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H2, output_size)  \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x).sum(dim=1)\n",
    "        output = self.linear(emb)\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n",
      "NEWS_NET2(\n",
      "  (embeddings): Embedding(10000, 150)\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=150, out_features=130, bias=False)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=130, out_features=130, bias=False)\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=130, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Build model')\n",
    "model = NEWS_NET2(vocab_size, \n",
    "                            embedding_size,  \n",
    "                            output_size,\n",
    "                            H1,\n",
    "                            H2).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=0.01)#5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    correct = (preds.argmax(dim=1) == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | loss 58.6325 | accuacy 0.4565\n",
      "epoch 1 | loss 34.6760 | accuacy 0.2643\n",
      "epoch 2 | loss 321.9044 | accuacy 0.2763\n",
      "epoch 3 | loss 356.3279 | accuacy 0.2658\n",
      "epoch 4 | loss 118.6474 | accuacy 0.4429\n",
      "epoch 5 | loss 31.3296 | accuacy 0.4745\n",
      "epoch 6 | loss 38.3063 | accuacy 0.4805\n",
      "epoch 7 | loss 33.4636 | accuacy 0.4550\n",
      "epoch 8 | loss 24.3657 | accuacy 0.3694\n",
      "epoch 9 | loss 17.5600 | accuacy 0.4324\n",
      "epoch 10 | loss 8.4467 | accuacy 0.3213\n",
      "epoch 11 | loss 8.8957 | accuacy 0.4039\n",
      "epoch 12 | loss 6.0330 | accuacy 0.4745\n",
      "epoch 13 | loss 5.1943 | accuacy 0.4189\n",
      "epoch 14 | loss 2.7437 | accuacy 0.3303\n",
      "epoch 15 | loss 3.3030 | accuacy 0.3408\n",
      "epoch 16 | loss 2.6113 | accuacy 0.3919\n",
      "epoch 17 | loss 1.6036 | accuacy 0.4955\n",
      "epoch 18 | loss 1.3213 | accuacy 0.4489\n",
      "epoch 19 | loss 1.4934 | accuacy 0.4880\n",
      "epoch 20 | loss 1.3056 | accuacy 0.5105\n",
      "epoch 21 | loss 1.1304 | accuacy 0.3859\n",
      "epoch 22 | loss 3.3619 | accuacy 0.5195\n",
      "epoch 23 | loss 1.1744 | accuacy 0.4625\n",
      "epoch 24 | loss 1.0785 | accuacy 0.4880\n",
      "epoch 25 | loss 1.0604 | accuacy 0.4865\n",
      "epoch 26 | loss 1.0963 | accuacy 0.4895\n",
      "epoch 27 | loss 1.0890 | accuacy 0.4489\n",
      "epoch 28 | loss 1.0864 | accuacy 0.4715\n",
      "epoch 29 | loss 1.0261 | accuacy 0.4820\n",
      "epoch 30 | loss 1.0759 | accuacy 0.5045\n",
      "epoch 31 | loss 1.0362 | accuacy 0.4820\n",
      "epoch 32 | loss 1.0188 | accuacy 0.4925\n",
      "epoch 33 | loss 0.9836 | accuacy 0.5045\n",
      "epoch 34 | loss 0.9670 | accuacy 0.5000\n",
      "epoch 35 | loss 1.1459 | accuacy 0.5375\n",
      "epoch 36 | loss 0.9587 | accuacy 0.5060\n",
      "epoch 37 | loss 0.9655 | accuacy 0.5315\n",
      "epoch 38 | loss 3.9625 | accuacy 0.5000\n",
      "epoch 39 | loss 1.0332 | accuacy 0.4865\n",
      "epoch 40 | loss 1.0491 | accuacy 0.4850\n",
      "epoch 41 | loss 1.0709 | accuacy 0.4429\n",
      "epoch 42 | loss 2.2402 | accuacy 0.3589\n",
      "epoch 43 | loss 1.5717 | accuacy 0.5105\n",
      "epoch 44 | loss 1.2675 | accuacy 0.5045\n",
      "epoch 45 | loss 1.2334 | accuacy 0.5060\n",
      "epoch 46 | loss 1.2740 | accuacy 0.4790\n",
      "epoch 47 | loss 1.1460 | accuacy 0.4309\n",
      "epoch 48 | loss 1.1876 | accuacy 0.4354\n",
      "epoch 49 | loss 1.1362 | accuacy 0.4670\n",
      "epoch 50 | loss 1.1380 | accuacy 0.5060\n",
      "epoch 51 | loss 1.0933 | accuacy 0.5120\n",
      "epoch 52 | loss 1.0867 | accuacy 0.4790\n",
      "epoch 53 | loss 1.1114 | accuacy 0.4955\n",
      "epoch 54 | loss 1.0763 | accuacy 0.4970\n",
      "epoch 55 | loss 1.0632 | accuacy 0.4865\n",
      "epoch 56 | loss 1.0216 | accuacy 0.4745\n",
      "epoch 57 | loss 1.0349 | accuacy 0.5360\n",
      "epoch 58 | loss 1.0083 | accuacy 0.5000\n",
      "epoch 59 | loss 0.9783 | accuacy 0.5135\n",
      "epoch 60 | loss 0.9834 | accuacy 0.5120\n",
      "epoch 61 | loss 0.9875 | accuacy 0.4955\n",
      "epoch 62 | loss 0.9734 | accuacy 0.5345\n",
      "epoch 63 | loss 0.9909 | accuacy 0.5060\n",
      "epoch 64 | loss 0.9586 | accuacy 0.5090\n",
      "epoch 65 | loss 0.9409 | accuacy 0.5210\n",
      "epoch 66 | loss 0.9429 | accuacy 0.5165\n",
      "epoch 67 | loss 0.9443 | accuacy 0.5345\n",
      "epoch 68 | loss 0.9339 | accuacy 0.5646\n",
      "epoch 69 | loss 0.9308 | accuacy 0.5541\n",
      "epoch 70 | loss 0.9079 | accuacy 0.5405\n",
      "epoch 71 | loss 0.9058 | accuacy 0.5586\n",
      "epoch 72 | loss 0.8982 | accuacy 0.5556\n",
      "epoch 73 | loss 0.9018 | accuacy 0.5646\n",
      "epoch 74 | loss 0.8820 | accuacy 0.5526\n",
      "epoch 75 | loss 0.8792 | accuacy 0.5931\n",
      "epoch 76 | loss 0.8827 | accuacy 0.5826\n",
      "epoch 77 | loss 0.8689 | accuacy 0.5946\n",
      "epoch 78 | loss 0.8675 | accuacy 0.6051\n",
      "epoch 79 | loss 0.8532 | accuacy 0.5946\n",
      "epoch 80 | loss 0.8300 | accuacy 0.6066\n",
      "epoch 81 | loss 0.8337 | accuacy 0.6321\n",
      "epoch 82 | loss 0.8285 | accuacy 0.6186\n",
      "epoch 83 | loss 0.8291 | accuacy 0.6246\n",
      "epoch 84 | loss 0.8037 | accuacy 0.6261\n",
      "epoch 85 | loss 0.8012 | accuacy 0.6411\n",
      "epoch 86 | loss 0.7643 | accuacy 0.6381\n",
      "epoch 87 | loss 0.7771 | accuacy 0.6622\n",
      "epoch 88 | loss 0.7467 | accuacy 0.6411\n",
      "epoch 89 | loss 0.7488 | accuacy 0.6396\n",
      "epoch 90 | loss 0.7318 | accuacy 0.6742\n",
      "epoch 91 | loss 0.7414 | accuacy 0.6592\n",
      "epoch 92 | loss 0.7049 | accuacy 0.6787\n",
      "epoch 93 | loss 0.6945 | accuacy 0.6532\n",
      "epoch 94 | loss 0.7150 | accuacy 0.6321\n",
      "epoch 95 | loss 0.7773 | accuacy 0.6351\n",
      "epoch 96 | loss 0.7560 | accuacy 0.6411\n",
      "epoch 97 | loss 0.7837 | accuacy 0.6727\n",
      "epoch 98 | loss 0.6720 | accuacy 0.4850\n",
      "epoch 99 | loss 1.0960 | accuacy 0.5736\n",
      "epoch 100 | loss 0.9395 | accuacy 0.5405\n",
      "epoch 101 | loss 0.9621 | accuacy 0.5435\n",
      "epoch 102 | loss 0.9420 | accuacy 0.5330\n",
      "epoch 103 | loss 0.9305 | accuacy 0.5330\n",
      "epoch 104 | loss 0.9284 | accuacy 0.5300\n",
      "epoch 105 | loss 0.9118 | accuacy 0.5360\n",
      "epoch 106 | loss 0.9129 | accuacy 0.5345\n",
      "epoch 107 | loss 0.8934 | accuacy 0.5345\n",
      "epoch 108 | loss 0.9008 | accuacy 0.5420\n",
      "epoch 109 | loss 0.9066 | accuacy 0.5435\n",
      "epoch 110 | loss 0.8864 | accuacy 0.5360\n",
      "epoch 111 | loss 0.8631 | accuacy 0.5420\n",
      "epoch 112 | loss 0.8762 | accuacy 0.5420\n",
      "epoch 113 | loss 0.8510 | accuacy 0.5420\n",
      "epoch 114 | loss 0.8647 | accuacy 0.5435\n",
      "epoch 115 | loss 0.8387 | accuacy 0.5511\n",
      "epoch 116 | loss 0.8318 | accuacy 0.5465\n",
      "epoch 117 | loss 0.8355 | accuacy 0.5495\n",
      "epoch 118 | loss 0.8212 | accuacy 0.5511\n",
      "epoch 119 | loss 0.8037 | accuacy 0.5465\n",
      "epoch 120 | loss 0.8184 | accuacy 0.5586\n",
      "epoch 121 | loss 0.7928 | accuacy 0.5631\n",
      "epoch 122 | loss 0.7706 | accuacy 0.5901\n",
      "epoch 123 | loss 0.7575 | accuacy 0.6216\n",
      "epoch 124 | loss 0.7247 | accuacy 0.6697\n",
      "epoch 125 | loss 0.7375 | accuacy 0.5631\n",
      "epoch 126 | loss 0.9591 | accuacy 0.6351\n",
      "epoch 127 | loss 0.7419 | accuacy 0.6502\n",
      "epoch 128 | loss 0.7958 | accuacy 0.6907\n",
      "epoch 129 | loss 0.6905 | accuacy 0.6276\n",
      "epoch 130 | loss 0.8212 | accuacy 0.5526\n",
      "epoch 131 | loss 1.1359 | accuacy 0.5360\n",
      "epoch 132 | loss 1.6793 | accuacy 0.5210\n",
      "epoch 133 | loss 1.3360 | accuacy 0.5315\n",
      "epoch 134 | loss 0.9550 | accuacy 0.4850\n",
      "epoch 135 | loss 1.0774 | accuacy 0.5285\n",
      "epoch 136 | loss 1.1192 | accuacy 0.4895\n",
      "epoch 137 | loss 1.0736 | accuacy 0.4700\n",
      "epoch 138 | loss 1.0765 | accuacy 0.5075\n",
      "epoch 139 | loss 1.1190 | accuacy 0.4985\n",
      "epoch 140 | loss 1.0838 | accuacy 0.5120\n",
      "epoch 141 | loss 1.0628 | accuacy 0.5045\n",
      "epoch 142 | loss 1.0791 | accuacy 0.5375\n",
      "epoch 143 | loss 1.0465 | accuacy 0.5285\n",
      "epoch 144 | loss 1.0907 | accuacy 0.5195\n",
      "epoch 145 | loss 1.0288 | accuacy 0.5390\n",
      "epoch 146 | loss 1.0351 | accuacy 0.5586\n",
      "epoch 147 | loss 1.0274 | accuacy 0.5435\n",
      "epoch 148 | loss 0.9980 | accuacy 0.5405\n",
      "epoch 149 | loss 1.0137 | accuacy 0.5330\n"
     ]
    }
   ],
   "source": [
    "# batchify\n",
    "x_train_batch = torch.split(x_train, batch_size, dim=0)\n",
    "y_train_batch = torch.split(y_train, batch_size, dim=0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i,(x,y) in enumerate(zip(x_train_batch, y_train_batch)):\n",
    "        y_pred = model.forward(x)#.squeeze(1)\n",
    "        loss = criterion(y_pred, y)\n",
    "        accuracy = binary_accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model.forward(x_train)\n",
    "        accuracy = binary_accuracy(y_pred, y_train)\n",
    "    print('epoch %d | loss %.4f | accuacy %.4f'%(epoch, loss.item(), accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train: 0.5225\n",
      "accuracy on test: 0.5030\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward(x_train)\n",
    "    accuracy = binary_accuracy(y_pred, y_train)\n",
    "    print('accuracy on train: %.4f'%(accuracy))\n",
    "    y_pred = model.forward(x_test)\n",
    "    accuracy = binary_accuracy(y_pred, y_test)\n",
    "    print('accuracy on test: %.4f'%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_c(aa):\n",
    "    bb = str(aa).split('tensor(')[1][:1]\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_pred = model.forward(hk_y_test)\n",
    "\n",
    "hk_pred2 = hk_pred.argmax(dim=1)\n",
    "\n",
    "hk_test['立場'] = list(hk_pred2)\n",
    "\n",
    "hk_test['立場'] = hk_test['立場'].apply(split_c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_test.to_csv(\"HK_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "udn_train_y = np.asarray(udn_train['立場']).astype(int)\n",
    "UDN_x_train, UDN_x_val, UDN_y_train, UDN_y_val = train_test_split(udn_train_corpus,  udn_train_y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n",
      "NEWS_NET2(\n",
      "  (embeddings): Embedding(10000, 150)\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=150, out_features=100, bias=False)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=100, out_features=100, bias=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=100, out_features=20, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 0 | loss 50.4661 | accuacy 0.2886\n",
      "epoch 1 | loss 2428.0806 | accuacy 0.3873\n",
      "epoch 2 | loss 11195.6035 | accuacy 0.3362\n",
      "epoch 3 | loss 7214.7041 | accuacy 0.3632\n",
      "epoch 4 | loss 1055.5381 | accuacy 0.3802\n",
      "epoch 5 | loss 592.4124 | accuacy 0.2935\n",
      "epoch 6 | loss 278.7814 | accuacy 0.3404\n",
      "epoch 7 | loss 40.3154 | accuacy 0.3475\n",
      "epoch 8 | loss 22.5436 | accuacy 0.3468\n",
      "epoch 9 | loss 17.0743 | accuacy 0.3454\n",
      "epoch 10 | loss 6.2663 | accuacy 0.3426\n",
      "epoch 11 | loss 3.2130 | accuacy 0.3404\n",
      "epoch 12 | loss 3.9153 | accuacy 0.3440\n",
      "epoch 13 | loss 2.6953 | accuacy 0.3433\n",
      "epoch 14 | loss 3.5902 | accuacy 0.3404\n",
      "epoch 15 | loss 3.7971 | accuacy 0.3419\n",
      "epoch 16 | loss 2.6498 | accuacy 0.3390\n",
      "epoch 17 | loss 7.0903 | accuacy 0.3397\n",
      "epoch 18 | loss 1.7773 | accuacy 0.3404\n",
      "epoch 19 | loss 1.7199 | accuacy 0.4016\n",
      "epoch 20 | loss 3.2020 | accuacy 0.3994\n",
      "epoch 21 | loss 2.0078 | accuacy 0.3980\n",
      "epoch 22 | loss 2.1595 | accuacy 0.3973\n",
      "epoch 23 | loss 1.4268 | accuacy 0.3994\n",
      "epoch 24 | loss 1.3730 | accuacy 0.4001\n",
      "epoch 25 | loss 1.3867 | accuacy 0.3973\n",
      "epoch 26 | loss 1.4862 | accuacy 0.3959\n",
      "epoch 27 | loss 1.4279 | accuacy 0.3987\n",
      "epoch 28 | loss 1.2632 | accuacy 0.3980\n",
      "epoch 29 | loss 1.2475 | accuacy 0.3980\n",
      "epoch 30 | loss 1.2322 | accuacy 0.3987\n",
      "epoch 31 | loss 1.2173 | accuacy 0.3994\n",
      "epoch 32 | loss 1.6282 | accuacy 0.3980\n",
      "epoch 33 | loss 1.5162 | accuacy 0.3980\n",
      "epoch 34 | loss 1.1938 | accuacy 0.3973\n",
      "epoch 35 | loss 1.1758 | accuacy 0.3966\n",
      "epoch 36 | loss 1.1706 | accuacy 0.3959\n",
      "epoch 37 | loss 1.1640 | accuacy 0.3959\n",
      "epoch 38 | loss 1.1583 | accuacy 0.3973\n",
      "epoch 39 | loss 1.1531 | accuacy 0.3966\n",
      "epoch 40 | loss 1.1475 | accuacy 0.3959\n",
      "epoch 41 | loss 1.1435 | accuacy 0.3973\n",
      "epoch 42 | loss 1.1487 | accuacy 0.3966\n",
      "epoch 43 | loss 1.1385 | accuacy 0.3966\n",
      "epoch 44 | loss 1.1346 | accuacy 0.3959\n",
      "epoch 45 | loss 1.1319 | accuacy 0.3959\n",
      "epoch 46 | loss 1.1295 | accuacy 0.3966\n",
      "epoch 47 | loss 1.1358 | accuacy 0.3959\n",
      "epoch 48 | loss 1.1253 | accuacy 0.3966\n",
      "epoch 49 | loss 1.1235 | accuacy 0.3959\n",
      "epoch 50 | loss 1.1219 | accuacy 0.3952\n",
      "epoch 51 | loss 1.1213 | accuacy 0.3959\n",
      "epoch 52 | loss 1.1218 | accuacy 0.3959\n",
      "epoch 53 | loss 1.1187 | accuacy 0.3959\n",
      "epoch 54 | loss 1.1175 | accuacy 0.3966\n",
      "epoch 55 | loss 1.1155 | accuacy 0.3966\n",
      "epoch 56 | loss 1.1164 | accuacy 0.3952\n",
      "epoch 57 | loss 1.1145 | accuacy 0.3959\n",
      "epoch 58 | loss 1.1135 | accuacy 0.3959\n",
      "epoch 59 | loss 1.1118 | accuacy 0.3959\n",
      "epoch 60 | loss 1.1120 | accuacy 0.3966\n",
      "epoch 61 | loss 1.1103 | accuacy 0.3966\n",
      "epoch 62 | loss 1.1097 | accuacy 0.3966\n",
      "epoch 63 | loss 1.1099 | accuacy 0.3966\n",
      "epoch 64 | loss 1.1084 | accuacy 0.3952\n",
      "epoch 65 | loss 1.1097 | accuacy 0.3959\n",
      "epoch 66 | loss 1.1072 | accuacy 0.3952\n",
      "epoch 67 | loss 1.1067 | accuacy 0.3966\n",
      "epoch 68 | loss 1.1081 | accuacy 0.3966\n",
      "epoch 69 | loss 1.1065 | accuacy 0.3952\n",
      "epoch 70 | loss 1.1053 | accuacy 0.3959\n",
      "epoch 71 | loss 1.1067 | accuacy 0.3959\n",
      "epoch 72 | loss 1.1044 | accuacy 0.3966\n",
      "epoch 73 | loss 1.1050 | accuacy 0.3945\n",
      "epoch 74 | loss 1.1046 | accuacy 0.3959\n",
      "epoch 75 | loss 1.1033 | accuacy 0.3966\n",
      "epoch 76 | loss 1.1039 | accuacy 0.3952\n",
      "epoch 77 | loss 1.1036 | accuacy 0.3959\n",
      "epoch 78 | loss 1.1023 | accuacy 0.3945\n",
      "epoch 79 | loss 1.1020 | accuacy 0.3966\n",
      "epoch 80 | loss 1.1017 | accuacy 0.3959\n",
      "epoch 81 | loss 1.1024 | accuacy 0.3952\n",
      "epoch 82 | loss 1.1021 | accuacy 0.3959\n",
      "epoch 83 | loss 1.1016 | accuacy 0.3959\n",
      "epoch 84 | loss 1.1006 | accuacy 0.3959\n",
      "epoch 85 | loss 1.1020 | accuacy 0.3945\n",
      "epoch 86 | loss 1.1010 | accuacy 0.3952\n",
      "epoch 87 | loss 1.1006 | accuacy 0.3959\n",
      "epoch 88 | loss 1.1005 | accuacy 0.3966\n",
      "epoch 89 | loss 1.0994 | accuacy 0.3959\n",
      "epoch 90 | loss 1.1001 | accuacy 0.3966\n",
      "epoch 91 | loss 1.0999 | accuacy 0.3952\n",
      "epoch 92 | loss 1.0987 | accuacy 0.3966\n",
      "epoch 93 | loss 1.0994 | accuacy 0.3966\n",
      "epoch 94 | loss 1.0983 | accuacy 0.3952\n",
      "epoch 95 | loss 1.0981 | accuacy 0.3966\n",
      "epoch 96 | loss 1.0988 | accuacy 0.3959\n",
      "epoch 97 | loss 1.0985 | accuacy 0.3945\n",
      "epoch 98 | loss 1.0975 | accuacy 0.3966\n",
      "epoch 99 | loss 1.0973 | accuacy 0.3966\n",
      "epoch 100 | loss 1.0972 | accuacy 0.3959\n",
      "epoch 101 | loss 1.0987 | accuacy 0.3959\n",
      "epoch 102 | loss 1.0968 | accuacy 0.3966\n",
      "epoch 103 | loss 1.0976 | accuacy 0.3959\n",
      "epoch 104 | loss 1.0984 | accuacy 0.3959\n",
      "epoch 105 | loss 1.0972 | accuacy 0.3959\n",
      "epoch 106 | loss 1.0971 | accuacy 0.3959\n",
      "epoch 107 | loss 1.0969 | accuacy 0.3959\n",
      "epoch 108 | loss 1.0958 | accuacy 0.3952\n",
      "epoch 109 | loss 1.0957 | accuacy 0.3959\n",
      "epoch 110 | loss 1.0963 | accuacy 0.3959\n",
      "epoch 111 | loss 1.0954 | accuacy 0.3959\n",
      "epoch 112 | loss 1.0953 | accuacy 0.3952\n",
      "epoch 113 | loss 1.0961 | accuacy 0.3966\n",
      "epoch 114 | loss 1.0950 | accuacy 0.3959\n",
      "epoch 115 | loss 1.0958 | accuacy 0.3959\n",
      "epoch 116 | loss 1.0947 | accuacy 0.3966\n",
      "epoch 117 | loss 1.0946 | accuacy 0.3959\n",
      "epoch 118 | loss 1.0945 | accuacy 0.3959\n",
      "epoch 119 | loss 1.0961 | accuacy 0.3966\n",
      "epoch 120 | loss 1.0961 | accuacy 0.3966\n",
      "epoch 121 | loss 1.0949 | accuacy 0.3959\n",
      "epoch 122 | loss 1.0948 | accuacy 0.3952\n",
      "epoch 123 | loss 1.0939 | accuacy 0.3959\n",
      "epoch 124 | loss 1.0937 | accuacy 0.3952\n",
      "epoch 125 | loss 1.0936 | accuacy 0.3959\n",
      "epoch 126 | loss 1.0945 | accuacy 0.3966\n",
      "epoch 127 | loss 1.0951 | accuacy 0.3959\n",
      "epoch 128 | loss 1.0950 | accuacy 0.3959\n",
      "epoch 129 | loss 1.0932 | accuacy 0.3966\n",
      "epoch 130 | loss 1.0931 | accuacy 0.3959\n",
      "epoch 131 | loss 1.0939 | accuacy 0.3966\n",
      "epoch 132 | loss 1.0955 | accuacy 0.3959\n",
      "epoch 133 | loss 1.0928 | accuacy 0.3959\n",
      "epoch 134 | loss 1.0927 | accuacy 0.3966\n",
      "epoch 135 | loss 1.0935 | accuacy 0.3959\n",
      "epoch 136 | loss 1.0925 | accuacy 0.3952\n",
      "epoch 137 | loss 1.0924 | accuacy 0.3959\n",
      "epoch 138 | loss 1.0923 | accuacy 0.3966\n",
      "epoch 139 | loss 1.0922 | accuacy 0.3959\n",
      "epoch 140 | loss 1.0940 | accuacy 0.3959\n",
      "epoch 141 | loss 1.0920 | accuacy 0.3959\n",
      "epoch 142 | loss 1.0919 | accuacy 0.3966\n",
      "epoch 143 | loss 1.0937 | accuacy 0.3959\n",
      "epoch 144 | loss 1.0927 | accuacy 0.3945\n",
      "epoch 145 | loss 1.0926 | accuacy 0.3959\n",
      "epoch 146 | loss 1.0935 | accuacy 0.3966\n",
      "epoch 147 | loss 1.0915 | accuacy 0.3959\n",
      "epoch 148 | loss 1.0914 | accuacy 0.3959\n",
      "epoch 149 | loss 1.0923 | accuacy 0.3952\n",
      "accuracy on train: 0.3952\n",
      "accuracy on test: 0.3807\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "sentence_max_lenght = 200\n",
    "embedding_size = 150\n",
    "output_size = 20\n",
    "epochs = 150\n",
    "batch_size = 3000\n",
    "H1 = 100\n",
    "H2 = 100\n",
    "\n",
    "x_train, y_train = torch.LongTensor(UDN_x_train).to(device), torch.LongTensor(UDN_y_train).to(device)\n",
    "x_test, y_test = torch.LongTensor(UDN_x_val).to(device), torch.LongTensor(UDN_y_val).to(device)\n",
    "\n",
    "class NEWS_NET2(torch.nn.Module):\n",
    "    def __init__(self, vocab_size,\n",
    "                 embedding_size,\n",
    "                 output_size,\n",
    "                 H1,\n",
    "                 H2):\n",
    "        super(NEWS_NET2, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size , embedding_size)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_size, H1, bias=False),\n",
    "            torch.nn.Dropout(0.2),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H1, H2, bias=False),\n",
    "            torch.nn.Dropout(0.2),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H2, output_size)  \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x).sum(dim=1)\n",
    "        output = self.linear(emb)\n",
    "             \n",
    "        return output\n",
    "\n",
    "print('Build model')\n",
    "model = NEWS_NET2(vocab_size, \n",
    "                            embedding_size, \n",
    "                            output_size,\n",
    "                            H1,\n",
    "                            H2).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=0.1)#5e-4\n",
    "\n",
    "# batchify\n",
    "x_train_batch = torch.split(x_train, batch_size, dim=0)\n",
    "y_train_batch = torch.split(y_train, batch_size, dim=0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i,(x,y) in enumerate(zip(x_train_batch, y_train_batch)):\n",
    "        y_pred = model.forward(x)#.squeeze(1)\n",
    "        loss = criterion(y_pred, y)\n",
    "        accuracy = binary_accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model.forward(x_train)\n",
    "        accuracy = binary_accuracy(y_pred, y_train)\n",
    "    print('epoch %d | loss %.4f | accuacy %.4f'%(epoch, loss.item(), accuracy.item()))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(x_train)\n",
    "    accuracy = binary_accuracy(y_pred, y_train)\n",
    "    print('accuracy on train: %.4f'%(accuracy))\n",
    "    y_pred = model.forward(x_test)\n",
    "    accuracy = binary_accuracy(y_pred, y_test)\n",
    "    print('accuracy on test: %.4f'%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "udn_pred = model.forward(udn_y_test)\n",
    "\n",
    "udn_pred2 = udn_pred.argmax(dim=1)\n",
    "\n",
    "udn_test['立場'] = list(udn_pred2)\n",
    "\n",
    "udn_test['立場'] = udn_test['立場'].apply(split_c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "udn_test.to_csv(\"UDN_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_train_y = np.asarray(bbc_train['立場']).astype(int)\n",
    "BBC_x_train, BBC_x_val, BBC_y_train, BBC_y_val = train_test_split(bbc_train_corpus,  bbc_train_y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n",
      "NEWS_NET2(\n",
      "  (embeddings): Embedding(10000, 150)\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=150, out_features=150, bias=False)\n",
      "    (1): Dropout(p=0.8, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=150, out_features=150, bias=False)\n",
      "    (4): Dropout(p=0.8, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=150, out_features=20, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 0 | loss 70.7464 | accuacy 0.2963\n",
      "epoch 1 | loss 27.2019 | accuacy 0.4127\n",
      "epoch 2 | loss 23.2336 | accuacy 0.3915\n",
      "epoch 3 | loss 27.1990 | accuacy 0.4497\n",
      "epoch 4 | loss 18.7604 | accuacy 0.4074\n",
      "epoch 5 | loss 19.4736 | accuacy 0.3968\n",
      "epoch 6 | loss 14.7455 | accuacy 0.3968\n",
      "epoch 7 | loss 14.5973 | accuacy 0.4286\n",
      "epoch 8 | loss 5.3956 | accuacy 0.4444\n",
      "epoch 9 | loss 4.0218 | accuacy 0.4550\n",
      "epoch 10 | loss 2.8124 | accuacy 0.4550\n",
      "epoch 11 | loss 3.0245 | accuacy 0.4339\n",
      "epoch 12 | loss 3.1632 | accuacy 0.4762\n",
      "epoch 13 | loss 2.6070 | accuacy 0.4868\n",
      "epoch 14 | loss 2.6496 | accuacy 0.4868\n",
      "epoch 15 | loss 2.5321 | accuacy 0.5185\n",
      "epoch 16 | loss 2.9423 | accuacy 0.5291\n",
      "epoch 17 | loss 2.5755 | accuacy 0.4709\n",
      "epoch 18 | loss 2.7288 | accuacy 0.4709\n",
      "epoch 19 | loss 2.9078 | accuacy 0.4974\n",
      "epoch 20 | loss 2.9455 | accuacy 0.5079\n",
      "epoch 21 | loss 2.9712 | accuacy 0.4762\n",
      "epoch 22 | loss 2.6414 | accuacy 0.4762\n",
      "epoch 23 | loss 2.6016 | accuacy 0.5132\n",
      "epoch 24 | loss 2.5044 | accuacy 0.4815\n",
      "epoch 25 | loss 2.7953 | accuacy 0.5132\n",
      "epoch 26 | loss 2.6641 | accuacy 0.4868\n",
      "epoch 27 | loss 2.5865 | accuacy 0.5185\n",
      "epoch 28 | loss 2.5961 | accuacy 0.4762\n",
      "epoch 29 | loss 2.4861 | accuacy 0.4974\n",
      "epoch 30 | loss 2.8402 | accuacy 0.5132\n",
      "epoch 31 | loss 2.7241 | accuacy 0.5026\n",
      "epoch 32 | loss 2.4605 | accuacy 0.5132\n",
      "epoch 33 | loss 2.6240 | accuacy 0.5026\n",
      "epoch 34 | loss 2.3636 | accuacy 0.5185\n",
      "epoch 35 | loss 2.9894 | accuacy 0.4921\n",
      "epoch 36 | loss 2.5282 | accuacy 0.5291\n",
      "epoch 37 | loss 2.3879 | accuacy 0.5079\n",
      "epoch 38 | loss 2.4941 | accuacy 0.5132\n",
      "epoch 39 | loss 2.2693 | accuacy 0.5344\n",
      "epoch 40 | loss 2.3525 | accuacy 0.5026\n",
      "epoch 41 | loss 2.2891 | accuacy 0.5079\n",
      "epoch 42 | loss 2.5450 | accuacy 0.5026\n",
      "epoch 43 | loss 2.5434 | accuacy 0.4974\n",
      "epoch 44 | loss 2.2213 | accuacy 0.4974\n",
      "epoch 45 | loss 2.3666 | accuacy 0.5132\n",
      "epoch 46 | loss 2.2137 | accuacy 0.5026\n",
      "epoch 47 | loss 2.1681 | accuacy 0.5132\n",
      "epoch 48 | loss 2.2303 | accuacy 0.5132\n",
      "epoch 49 | loss 2.1195 | accuacy 0.5185\n",
      "epoch 50 | loss 2.5327 | accuacy 0.5132\n",
      "epoch 51 | loss 2.2115 | accuacy 0.5132\n",
      "epoch 52 | loss 2.4008 | accuacy 0.5238\n",
      "epoch 53 | loss 2.4168 | accuacy 0.5132\n",
      "epoch 54 | loss 2.0470 | accuacy 0.5132\n",
      "epoch 55 | loss 2.2364 | accuacy 0.5079\n",
      "epoch 56 | loss 2.4271 | accuacy 0.5132\n",
      "epoch 57 | loss 2.1309 | accuacy 0.4921\n",
      "epoch 58 | loss 1.9827 | accuacy 0.5185\n",
      "epoch 59 | loss 1.9876 | accuacy 0.5079\n",
      "epoch 60 | loss 2.0612 | accuacy 0.5132\n",
      "epoch 61 | loss 1.9058 | accuacy 0.5026\n",
      "epoch 62 | loss 1.9969 | accuacy 0.5238\n",
      "epoch 63 | loss 1.9596 | accuacy 0.5079\n",
      "epoch 64 | loss 1.9501 | accuacy 0.5291\n",
      "epoch 65 | loss 1.9321 | accuacy 0.5344\n",
      "epoch 66 | loss 1.9164 | accuacy 0.4974\n",
      "epoch 67 | loss 1.8980 | accuacy 0.5132\n",
      "epoch 68 | loss 1.9561 | accuacy 0.5026\n",
      "epoch 69 | loss 1.8788 | accuacy 0.5026\n",
      "epoch 70 | loss 2.0768 | accuacy 0.5291\n",
      "epoch 71 | loss 2.1361 | accuacy 0.5132\n",
      "epoch 72 | loss 1.8822 | accuacy 0.5132\n",
      "epoch 73 | loss 1.8256 | accuacy 0.5132\n",
      "epoch 74 | loss 1.9463 | accuacy 0.5079\n",
      "epoch 75 | loss 1.7873 | accuacy 0.5079\n",
      "epoch 76 | loss 1.8313 | accuacy 0.5185\n",
      "epoch 77 | loss 1.7903 | accuacy 0.5238\n",
      "epoch 78 | loss 1.8113 | accuacy 0.5238\n",
      "epoch 79 | loss 1.9243 | accuacy 0.5079\n",
      "epoch 80 | loss 1.8212 | accuacy 0.5238\n",
      "epoch 81 | loss 1.7845 | accuacy 0.5079\n",
      "epoch 82 | loss 1.8090 | accuacy 0.5185\n",
      "epoch 83 | loss 1.8412 | accuacy 0.5238\n",
      "epoch 84 | loss 1.7387 | accuacy 0.5132\n",
      "epoch 85 | loss 1.7324 | accuacy 0.5132\n",
      "epoch 86 | loss 1.7444 | accuacy 0.5291\n",
      "epoch 87 | loss 1.7156 | accuacy 0.5079\n",
      "epoch 88 | loss 1.7181 | accuacy 0.5079\n",
      "epoch 89 | loss 1.7084 | accuacy 0.4974\n",
      "epoch 90 | loss 1.7134 | accuacy 0.5132\n",
      "epoch 91 | loss 1.7695 | accuacy 0.5291\n",
      "epoch 92 | loss 1.6136 | accuacy 0.5079\n",
      "epoch 93 | loss 1.6717 | accuacy 0.5291\n",
      "epoch 94 | loss 1.8548 | accuacy 0.5026\n",
      "epoch 95 | loss 1.7837 | accuacy 0.5238\n",
      "epoch 96 | loss 1.7097 | accuacy 0.5079\n",
      "epoch 97 | loss 1.6079 | accuacy 0.5291\n",
      "epoch 98 | loss 1.7915 | accuacy 0.5185\n",
      "epoch 99 | loss 1.5919 | accuacy 0.5185\n",
      "accuracy on train: 0.5238\n",
      "accuracy on test: 0.4375\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "sentence_max_lenght = 200\n",
    "embedding_size = 150\n",
    "output_size = 20\n",
    "epochs = 100\n",
    "batch_size = 3000\n",
    "H1 = 150\n",
    "H2 = 150\n",
    "\n",
    "x_train, y_train = torch.LongTensor(BBC_x_train).to(device), torch.LongTensor(BBC_y_train).to(device)\n",
    "x_test, y_test = torch.LongTensor(BBC_x_val).to(device), torch.LongTensor(BBC_y_val).to(device)\n",
    "\n",
    "class NEWS_NET2(torch.nn.Module):\n",
    "    def __init__(self, vocab_size,\n",
    "                 embedding_size,\n",
    "                 output_size,\n",
    "                 H1,\n",
    "                 H2):\n",
    "        super(NEWS_NET2, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size , embedding_size)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_size, H1, bias=False),\n",
    "            torch.nn.Dropout(0.8),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H1, H2, bias=False),\n",
    "            torch.nn.Dropout(0.8),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H2, output_size)  \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embeddings(x).sum(dim=1)\n",
    "        output = self.linear(emb)\n",
    "             \n",
    "        return output\n",
    "\n",
    "print('Build model')\n",
    "model = NEWS_NET2(vocab_size, \n",
    "                            embedding_size, \n",
    "                            output_size,\n",
    "                            H1,\n",
    "                            H2).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=0.01)#5e-4\n",
    "\n",
    "# batchify\n",
    "x_train_batch = torch.split(x_train, batch_size, dim=0)\n",
    "y_train_batch = torch.split(y_train, batch_size, dim=0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i,(x,y) in enumerate(zip(x_train_batch, y_train_batch)):\n",
    "        y_pred = model.forward(x)#.squeeze(1)\n",
    "        loss = criterion(y_pred, y)\n",
    "        accuracy = binary_accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model.forward(x_train)\n",
    "        accuracy = binary_accuracy(y_pred, y_train)\n",
    "    print('epoch %d | loss %.4f | accuacy %.4f'%(epoch, loss.item(), accuracy.item()))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(x_train)\n",
    "    accuracy = binary_accuracy(y_pred, y_train)\n",
    "    print('accuracy on train: %.4f'%(accuracy))\n",
    "    y_pred2 = model.forward(x_test)\n",
    "    accuracy = binary_accuracy(y_pred2, y_test)\n",
    "    print('accuracy on test: %.4f'%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_pred = model.forward(bbc_y_test)\n",
    "\n",
    "bbc_pred2 = bbc_pred.argmax(dim=1)\n",
    "\n",
    "bbc_test['立場'] = list(bbc_pred2)\n",
    "\n",
    "bbc_test['立場'] = bbc_test['立場'].apply(split_c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_test.to_csv(\"BBC_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 貝葉氏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountVectorizer_MultinomialNB(df, test_df_series, alpha = 0.3):\n",
    "    y = np.asarray(df['立場']).astype(int)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df['內容'],  y, test_size = 0.2, random_state = 0)\n",
    "    cv = CountVectorizer()\n",
    "    x_train_cv =cv.fit_transform(x_train).toarray()\n",
    "    x_test_cv = cv.transform(x_test)\n",
    "    x_real_test_cv = cv.transform(test_df_series)\n",
    "    \n",
    "    naive_bayes = MultinomialNB(alpha)\n",
    "    naive_bayes.fit(x_train_cv, y_train)\n",
    "    predictions = naive_bayes.predict(x_test_cv)\n",
    "    predictions2 = naive_bayes.predict(x_real_test_cv)\n",
    "    \n",
    "    print(\"Accuracy score:\", accuracy_score(y_test, predictions))\n",
    "    print(\"Precision score:\", precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Recall score:\", recall_score(y_test, predictions, average='micro'))\n",
    "\n",
    "    %matplotlib inline\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    sns.heatmap(cm, square=True, annot=True, cmap=\"RdBu\", cbar=False,\n",
    "    xticklabels=[\"反對\", \"中立\",\"支持\"], yticklabels=[\"反對\", \"中立\",\"支持\"])\n",
    "    plt.xlabel(\"true label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "    return predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5748502994011976\n",
      "Precision score: 0.5748502994011976\n",
      "Recall score: 0.5748502994011976\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAEOCAYAAAB4sfmlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGWBJREFUeJzt3XmYFOW5/vHvMzMMwwwwDPsiKmBQRJEo7iLgguKS4HISNWo0GoxL3EIMnOhBTVxxIaIe5YdixF1+Imo0guASxYgbgopLiCKKKKCyjSyDz/mjakyLzNCv0F3VcH+ui2u6q7fbEe6ueqvqLXN3RERCFCUdQEQKj4pDRIKpOEQkmIpDRIKpOEQkmIpDRIKpOEQkmIpDRIKpOEQkWEnSAbL1ZNeddYhrPRZ9uSLpCKn33MLqpCOk3i3+oWXzPK1xiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxiEgwFYeIBFNxBCquKKesXdukY6RWSUU55R3aJR1DckzFkaWSpk3oedM19J40gbYDDgSgrEM7+r00hV3HjmLXsaNo99NDE06ZnAaVTel9xw0cPu3vbPnTgwGo6tGNfg+O5oBH7qTPXTdR0rgi4ZTpsf95p/D758cxZNoEdjvup0nHCVaSdIBC4WvWMHvkrTTpth2lVc2+Xf7V9Jm8fto5CSZLB6+pYebwm6jasRsNm1cBsHT2HJ7+r1MB2OF3p7PVwAHMvmtckjFToWqLdvQc2J/h+xxNg7KGXPjGE0y7Z0LSsYLkZY3DzMrMrFs+PitX1iyvZuk77ycdI7Vqllfz1Vvvfm8ZgBUXU9GxPV+9/V4S0VKnZtVqiktLsaIiSivKWf7F4qQjBcv5GoeZ/Q6oBHYys2cBAzx+eJa7P5HrDLniNWso79iB3e4bw/LZ/+bdq0ZQs2Rp0rFSZa9brqbtvnvy4bhHWfTajKTjpMLSzxcyZcTtnP/MfRQVF3P3oKFJRwqWjzWO0cC9wLT49mjgEeA2YEgePj9nVn72OS8ccjTTjjmZpe+8R9fBZycdKXWm/uYCxvfoB8C2g45POE06NGxcQc8jDuKBsy/hhdH30eeME5KOFCznxeHui4ElwNfAVsAwoEu8/Kn6Xmtmg8zsFTN75fHFC3MddYN8Mm4CTbbrmnSMVPKaGmbf/RAte/VMOkoq7H78Ebwz+QXmTn+LqWMepLyqkvbdC+vvTs6Lw8x+BmwPNAI+Af4XeN/MtgWuqe+17j7K3Xu5e69DKlvmOmqwkiaNv73dar99WfL2OwmmSZ8mnbf69nbbPnuwaPpbCaZJj5pVq2jTtRMAVlREVcd2rFxWnXCqMPnYqzIH2Bo4lmitYz5wKjAY6Aa8locMG6xBZVN63ngNpa1aUFRSQqt+vfn0sSfpeOxR1CxdxspFXzBr2OVJx0xMabNKet/xF8pat6SopIQO/fsw97FJ7D3qGlYtWcqS9z/g1T9ekXTMVHhp7Hh+OWY4F7w4nm9qaph213gWzfk46VhBzN3X/6wN+QCz/kQDopcSlcdw4MfAeOBVd78nm/d5suvOuQ1a4BZ9uSLpCKn33MLC+lZPwi3+oWXzvHwMju4J7EG0Z+XnwEPAh8AFRGMeIlJg8lEczxMVxRfA2HjZcndfA1Tl4fNFZCPLR3HMc/e/Ake7+8fAeHc/PH7sRjPbKQ8ZRGQjykdx3BT/PM/MLgVaZTy241r3RaQA5PMkt17ASOCXZjbUzAzoD0zOYwYR2QjyepKbuy8ALjWzHwN3A095rnfriMhGl9Rp9Z8C5cBXCX2+iGyAvBeHmR0FnAMcB/TN9+eLyIbLa3GY2QhggbsPdfdq4J9mtnM+M4jIhstHcbQzsxOBtsA/gSoz62VmjYDHAE0LJVJg8jE4ethaPxsB7Yk2VyqJ9rSISAHJeXG4++x1LH4TmBivdZTlOoOIbFyJzjnq7l8TnTErIgVEs5yLSDAVh4gEU3GISDAVh4gEU3GISDAVh4gEU3GISDAVh4gEU3GISDAVh4gEU3GISDAVh4gEU3GISDAVh4gEU3GISDAVh4gEU3GISDAVh4gES3TqwBCTPtC1m+pzww59k46Qer9aOCXpCJsMrXGISDAVh4gEU3GISLA6xzjM7FGgrivJG+Du/pOcpBKRVKtvcPSsvKUQkYJSZ3G4+5za22bWAPgl0MbdLzOz1kBxHvKJSAplO8ZxB9GlGg+N73u8TEQ2Q9kWR2t3vxFYCeDuC4CGOUslIqmWbXGsMLOWxIOlZrYjUJqzVCKSatkeOXo2MAroYWZTiTZbfpWzVCKSalkVh7t/ABxpZo2BIndfkttYIpJmWRWHmbUALgJ2BarNbBLwF3dfmctwIpJO2Y5x3A28BhwIHEt0ANioXIUSkXTLtjjK3f1Od69294XufhWwVS6DiUh6ZVscb5vZNrV34gPAPspNJBFJu2zPVWkAvGZm04DVwG7A9NzHE5E00rkqIhIsq3NVAMzsR0BbooHRWt95johsHrLdHXsr0WDotsDfgb7ADOC5nCUTkdTKdnC0u7sfDDwNXAjsgs5VEdlsZVsc35hZEdGA6N7A10DHnKUSkVTLtjj+BHQC/gqcC8wCHspVKBFJt2zPVZmUcXe/HGURkQJR33EcI6l7zlEA3P3sjZ5IRFKvvjWOcXlLISIFpb7jOJ7NZxARKRy6roqIBFNxiEiw+gZHz1/fi939uo0bR0QKQX1rHIsy/nQD9gEWEx38NQBomfN0IpJK9Q2O/rX2tpkdBxzs7rWznI8GJuQ+noikUbaznDclvl5sfH8N0CYniQpA//85l2367kFRgxIeH3oV/37+5aQjpUKLZo0ZNexk2rSoZPGyaj5btISObZsDUFJcTMe2zdnmkN8nnDId9j/vFHY+agDFpQ2YMuJ2pt1TWN/D2RbHGGCimd0L1ADHAE/kLFWK/Wi/vanasj0373cM5S2qOPXR2xm595HEK2ObtZFDT+DWB59m4tQ3v/fYT/r+mJ7bbZlAqvSp2qIdPQf2Z/g+R9OgrCEXvvFEwRVHVntV3H0UcCbRGbEtgD+5+4W5DJZWHXpuz/tPTwWgetGXLP5kPi26aPrVti0raVxRts7SADhp4D78dcLzeU6VTjWrVlNcWooVFVFaUc7yLxYnHSlYVsURX3S6N1AV70n5l5m1y2mylJo38x12HHgQRcXFNG7Vgg49u1PRsirpWInr3qUD8xd8xf3XnMGU24ZwypF9vn2sfatmlJSUMOfTRQkmTI+lny9kyojbOf+Z+zjjkdHcPWho0pGC5e2i02b2vc0iM+sf8h5p8N6kfzD35Rn85ql7OPSKPzDvjbdZvvDLpGMlrmVVE3b40Rb8+uIxHHLGtRx/2F5069wegJMG9mbsI1rbqNWwcQU9jziIB86+hBdG30efM05IOlKwfF50euI6lg2p7wVmNsjMXjGzV2Z8k56Lx025+n+5ud/Puf/UC6ho2Zyv5s5LOlLiFny5lOdff48ly75mxcrVTHrxTbaPi+Pwvj9mwtOvJ5wwPXY//gjemfwCc6e/xdQxD1JeVUn77l2TjhUknxed7mBm15jZJWa2ZzYvcPdR7t7L3Xv1KGoa+HG5YWaYRdOu9jhqAPNmzKJm5aqEUyXvpRmz2bV7ZxqWlmBm7N6jCzPf/5gD9ujOC6+/z6rVNUlHTI2aVato07UTAFZURFXHdqxcVp1wqjA/5KLTLwCNgFMCP2ueuw82s4bAADO7FugS+B6JK6tswq//dgcAiz6Yy7jT/5hsoJRY/vVKRox9komjLuCbb5x7n3iR9+bMZ9jpA7li9KNJx0uVl8aO55djhnPBi+P5pqaGaXeNZ9Gcj5OOFcSy2Y1oZk3cfWnmRadrl2XxWgOOBM509/3Weuxpd++XTdDBDTprf2c9btihb9IRUu9X06ckHSH1bvEPbf3Pyn5TZQKAuy/LuFL9eo/jiEtjOPBpHU9RGYgUoHo3VczsDKLzUnY0s0cyHmoKrHdXQnyI+uD4vWrfszfR9IMNiOYxFZECs74xjrHA48C9wG8zlq9w988CP2vLeFzjcXe/BMDM9g58DxFJgXqLIx7DWGpmg4H57r4SwMwqzGwXd3814LM+dPffbUBWEUmJbMc4rq0tDQB3Xw5cG/JB7n7AOhYPC3kPEUmHbHfHrlzHsqyP4zCzG4HaQVUDmrj7We6uS0iKFKBsi2Oimd0CXEd0duxpwGsBn7N95q5YM9N+MZEClu0FmS4zs2OBS4gO/poC3JzLYCKSXtmuceDu9xLtXQliZgcBzTNOaLPM++6+rnNYRCTF6pus+NravSBmNpPvHqxlRIdp9MjiM1bEr10Rv4513BeRAlLfGscFtTfcfccf+gHu/qyZfZk5ELr2fREpLPUVx061R3vWxd2zHSBd+420piFSwOorjswjRVsD3YHniObh6AM8DRyb5efMNLPL49sGzAzMKSIpUt/lEU6uvW1mDwM9ak9wM7M2wPXZfoiuai+yacn2yNFmGWfFEp+noimrRTZT2e6OfdPM/kx0mYQa4BfA5zlLJSKplu0axznAHOAKYGS87MScJBKR1Mv2yNE1ZvYM8G93n5zbSCKSdtleV+UPwOVEs3lhZjua2Z25DCYi6ZXtpsoh7v5fRFerx91nosFRkc1WtsWxOp4/tPbyCE2Jpg8Ukc1QtsVxNTCOaPq/y4DnCZzIR0Q2Hdnujv0H8DKwN1AM3Ojudc1cLiKbuGyL41l33w14LJdhRKQwZLup8rCZnWJmHc2see2fnCYTkdTKdo3jwPjn8RnLnOj6KCKymcn2ALCsLtMoIpuHrIrDzFoBFwK9gGpgEvCXzEsmiMjmI9sxjruAV4k2WY4lmlPjllyFEpF0y7Y4yt39TnevdveF7n4Vuu6ryGYr2+KYZWbb1N6JJ/L5ODeRRCTtst2rsiXwqpm9DKwGdiOaDvAR/jPj+U9ylFFEUibb4jgtpymy0LVx1lec3CzN2rc66QipN+uzJklH2GRkuzt2Tq6DiEjhyHaMQ0TkWyoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCoOEQmm4hCRYCqOAA0aV1CxRbukYxScooomFDepTDpGahRXlFPWoW3SMTaIiiMLpZVNOXDsSH7+6pN0GTgAgEZtWnHAmBEc9uidDHzqAdr33j3hlAkzo8URJ9L+rP9hi8GXU9n3EEpatKbdb4ay5R+vp6zzdkknTFyDyqb0um0E+019nPaHH/Sdxyq26cTB/3qJyh7bJ5QuTEnSAQqBr1nDq1fdSMsdt6esRRUADZs15aVLrmXph3Mpb9uag++/hYf6HJlw0gQVFVP99nQWjb8TzNjid5ex/I1pLBh3O0169U46XSp8U1PDu9feTOUO3Sht3uw7j3X743ksfP6lhJKFy8sah5n1WOv+gHx87sayetlyvnjz3e8s++rd2Sz9cC4A1fM/p7i0NIlo6bGmhq/fnRHddqdm8ZdYSQk1Cz9LNleKrFlezdK33/ve8q1O/BmfPTmF1V8uSSDVD5OvTZURAGY23sw6A8PMrKuZbRIDBh0P6M3Hz0xNOkZqFDeppKisEasXzE86SuqVtW1Nq377MPe+h5OOEiTfYxzNgJ5AU2BX4HEzK+hxlsptOrHTuYN45bK/JB0lFaxBKa1POJOF//+OpKMUhG7DBjPrz9clHSNYzsc4zOxioJOZ/Qlwd3/IzH4L3A/sEmdYVcdrBwGDAH7RqA37Nmy2rqclpnHH9ux7w5+Y8uvBrF62POk4ySsuoc1J5/DV5EdZNe+jpNOkXvmWW9Ck6zZ0v/QPADTd7kdUdNmK6WcNpfqjjxNOV7+cF4e7X2xm+7r7RWY2JeOhE9z9/PW8dhQwCmBU1Xaey5yhGrVpRd+br+SZ04ew/BOtklNURJsTzmTJ1Ml8/e7MpNMUhOqPPua5/f8zoL7T9X/mwzH3pL40IH97VSz+OTfj/tN5+uwN1rBZJQeOHUl565YUNShhy4P6Uv3ZAsrbtqbPjZcDsGLhFzx18rkJJ01O0z360Wib7SluXEmzfocB8MXf7qP5ocdQ0rwVvmoFlb0P4tNbr8BXr044bTIaNGtKr9EjaNi6JVZSQpsD+jD9vIv4eu4nSUcLZu65/yI3s5bAHu7+mJmdDjzg7otC3iNtaxxps/+JPZOOkHqzHnwr6Qipd9i8mbb+Z+VnjOOK+OZOZrYX0AvYwcyWAOXufk6uM4jIxpWPMY6hAGZ2mrvfamZtgT+4+1AzeyLXny8iG1++DgDrD0wAcPf5wJj49gAz2yUfGURk48nXMRRD3H2+mRmAu88AiA8A2yNPGURkI8n3wVdTzOxqM2sc39+PAtq7IiKRJI7aHA5caWbNgJ3d/e0EMojIBsh5cZjZQUDzeJyjyt0XAP8N3AS8k+vPF5GNLx9rHMuANcDy+CdAGVAa/xGRApPz4nD3F4DF8c8lZtYFuAw4GdjezIpznUFENq4kxjhOBs5y92XARGCvBDKIyAbIV3HUHsZ6nbtf6O4r4/tTifasiEgByVdxDANw90czF8YDpQ/mKYOIbCR5KQ53f66ex7Q7VqTAFPTsWyKSDBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMBWHiARTcYhIMHP3pDMUJDMb5O6jks6RZvod1a+Qfz9a4/jhBiUdoADod1S/gv39qDhEJJiKQ0SCqTh+uILcNs0z/Y7qV7C/Hw2OikgwrXGISDAVh+SFmenv2iZE/zNlg5lZXzM7eD1PG25mxXkJJDmnMY46mNk2wGPA/DqecibQDtgH+CfwFbC1u99nZs2AU939mryETYCZjQR2jO82I/oS+iK+/7a7n7HW8/cG2rn7uPylTA8z2wdo7O5/X8djV7r7kIz7l7j7sLwGDFSSdICUu9Ld76jrQTPbNePu1sCXZrYF0BSoNLNyd6/ObcTELHf3vhCtcQBltf8ozOzK+Odkot/L3NoXmdlZQHtgHtDf3VflNXWemFkf4JKMRZVAsZkNyVh2ZcbvrBXwYLy8U/x6gHPdfXrOAwdScdRviJmdtI7lrwLXAacBLYBDgQrgXqJv4TKgJ9AJeCsvSVPI3fc3s+uB8z1j1dbMrnP38xOMlnPu/izQt/b+utY4zKy9mf2G6O/KnhlF/Gd3vzC/icOoOOp3KbCHu59du8DMWgNnE31j/gw4EbgfGAjcQfRt+hGwwt0329LI8DjQG3gOwMzKgOWJJsoTM/sJUFuQa69x7O/u84BbzGxrd3/EzO4Etoxf+wyw2N1/mu/c2VBx1K0R8DXwkJkdnbFtfjpwG1AO9AHmAFcDDwHNgZP57irqpqoi/ssN8RhHxj+KtzOe9xQwjLg4gAHA97bzN0VxGewBjHH39+HbL54L3H1NfL8tsIuZnenuJ9a+1syOAt5IInc2VBx1aw984u7TzOwqM3uBaDC0xt0/ADCzY4DGRNvxzYkGSScCrZKJnD/u/tva22uPcaz1PDezBhmLem/qmylruRS4ycz+m+iL6GJgCICZ7UT0RfMv4AEzexao3aRrAyyNB0r/lvfU66G9KnUws6HADe6+3MwqgHuI/sf/ovbbIn5eCTAcuJtowHDW5rBXJdO6imOtwcFOwAfx7S7A7Pj2lesqm02NmTUBxgCrgTPd/Yu1Hr/S3YeYWWegHzCWaDP4FXd/J++Bs6DiWAczKydavb6CaOBzT+AZolXyHsAkYAZwFtFu2DnAO0Sr6IOBA4n+UaTum0LyJ94s2QvoD8wCVgHbAq8Dk4FPgSeA99dag7se2A84xN0/yXfubKg41sHMmhONYXQGqt39lYzHioH9gQXu/npCESXlzKw70VrDFGCqu69e67H9gH+6+8vreG0Z0SZxTb7yhlJxiEgwHXIuIsFUHCISTMUhIsFUHCISTMUhOWNmF5vZ0fU8fpKZDQ54v6DnS+6oOASA+MhGkayoOKTWcUkHkMKh4hDMbDTRHBDPmFmfeBPjOjN71swOMLM3M57b18xujG+3MrMHzGyymT1iZi3q+Yzfm9k/zOw1Mzsl46EOZjbBzF4ys1tqpxg0s4Pi9/1HfPi/pIiKQ3D3U4EP3L1vPI8EQBt37+PuT9Xz0quAi9x9f+D/8Z9TyNflMXfvDexNdFh+rT7Ace6+O9AQGBgfuXsa0UQ/vYnOHt32h/3XSS7o7Fipy8QsnnMA0NnMIPq7VN/8IzVmdhGwA7BFxvKH3b12fo5xRFMxrgZ2AibH792MeJ4KSQcVh9Slrsl2Mk+R/3b6wPqYWUuis4fPAa4HXsl4OHPqwHKgGigGHnD372yi1DEbmyRAmyryLTMrreOh+fEp3xCtEdSabWaHxK9tbGad6nj91kSbQi8SrW10znhsgJk1iMc2TiKa+GcacLiZVcbv3eOH/PdI7miNQ2rdA7wSTya8tkuA2+NB0tUZy88GbosHL9fE99dlOlAWT4Y0g2jimlrvAQ8Tzd06Pi4XzOwq4BkzW0o0FePxP/i/TDY6nR0rIsG0qSIiwVQcIhJMxSEiwVQcIhJMxSEiwVQcIhJMxSEiwVQcIhJMxSEiwf4P7FEXgdPN26gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hk_preds = CountVectorizer_MultinomialNB(hk_train, hk_test['內容'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_preds2 = list(hk_preds)\n",
    "hk_test['立場'] = hk_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_test.to_csv(\"naive_beyes_hk.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5596590909090909\n",
      "Precision score: 0.5596590909090909\n",
      "Recall score: 0.5596590909090909\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAEOCAYAAAB4sfmlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGu9JREFUeJzt3XmYFPW5xfHvOwszDDDMsINIWFREBBQJLtGLK+6YRK9ejVFRo0YIGsUFg0FwRQRRBAV3oxKV64pLQFDcg4BGjBiVgMgqiGyDMNt7/6geMnJhqEK6qxvO53l4pqu6q/swMGeqfrWZuyMiEkVW3AFEJPOoOEQkMhWHiESm4hCRyFQcIhKZikNEIlNxiEhkKg4RiUzFISKR5cQdIKzZS1brENcajG7RJe4Iae/8Y9vGHSHtdX9tqoV5ndY4RCQyFYeIRKbiEJHIVBwiEpmKQ0QiU3GISGQqDhGJTMUhIpGpOEQkMhWHiESm4hCRyFQcIhKZikNEIlNxiEhkKg4RiUzFISKRqThEJDIVh4hEpuIQkchUHCISmYpDRCJTcYhIZCoOEYlMxSEikak4RCQyFYeIRKbiEJHIVBwiEpmKQ0QiU3GISGQqDtmh8urWoXj3FnHHkCTLiTtAJulz1q9o2LgpAO3a783qVd+zYtkyACorKljx7VLue/qlOCPGpqCokHMeGkbbQ7oyedg4Jg+/f9NzTdu347qZLzG8xxksmDk7xpQxysqi1YWXULDHHmTXLmDF1NdZ9twE8pq3oM1lV2K1arFx0UL+PXxo3ElDUXFEUKtWHkPuum+Lz01/+03mffVFihOlj4ryCl66YSSt9u9I3UbFP3ru10Ov5fMp78aULD1YdjarZkxnwbgxkJVFx7vGsPLNKbT5Y38WjB3D+rlfxR0xkpRsqphZvpl1SMVnxWXqqy9xxHEnxR0jNhvXlbDokzn/b/5/XXI2/3hhEutXro4hVfrwsjLWzJoRTFRWUvrdd9Rq0pQNixZlXGlACtY4zOxKoD7QxcymAQZ44uk57v5qsjPsKHULC/lT3wupW6+Qsy/qw+5t2gHw3fJvKS8vp0lzbdtXV9SiKR2P68G9v/wde/7XgXHHSRu5xcVkFxRQ0KYdlT+sZ6/BN5Ndpw5LJjzNqg/eizteKKnYVHkAaAFsTDw2oDGwHHgRyJjiuPHucQB8OeefjLzpeoY/+CSgtY2tOXX4QJ69+ta4Y6SVrLw82l41gK/vHUVR9wPJa7EbX950A1l5eXQYNpK1n86mYt3auGNuU9I3Vdx9NbAG+AH4GTAIaJeY/3pNy5rZRWY2w8xmTHj8kWRHDW3PDh3Jycll48YNuDsfvjON7of2iDtWWmnUZndadNyT0+8axB9efZQOxxzKGXffQKM2u8cdLTaWm0u7AX9myTNP8cO8f1O+ejVrPpqJl5VRsW4dJV98Tn6LzFhrTcWmyunA90BtYBFwL1BhZu2BO2pa1t3HAeMAZi9Z7TW9NtnKSkuprKwkLz+fpYsW4u7k5eXz8Ycf0KHTfuTWqhVnvLSzYt433Nj5uE3T5z58B2/c8ygr5n0TY6oYZWXR9qoBLH/lJdZ8NBOA1R/NonWffix78XksJ4farVqzYdHCmIOGk4pNla+B1sCZBGsdS4ELgf5AB2BWCjL8ZOvXl3DTVf2oXVBAdnYOl149EICpr7zIqb89P+Z08Ssors8lz46lsFljsnNz6HTSUTzauz/fzc+MH4Rka3zcCRR27kJuURHNTjsdgLlDb2HV9A/ocMdIAJY881cqSkrijBmauSf3F7mZ9SQY1xhCUB7DgP2B54CZ7v5kmPeJe40j3Y1u0SXuCGnv/GPbxh0h7XV/baqFeV0qdsceDBxEsGflDOBZYD5wNcGYh4hkmFQUxzsERbES+EtiXom7VwDFW1tIRNJXKopjsbs/Cpzm7guB59z95MRz95iZ1rFFMkwqimN04usfzWwIwTEcVTptNi0iGSCVZ8d2A0YB55rZADMzoCcwJYUZRGQHSOlJbu6+HBhiZvsDTwCve7J364jIDhfX9TiWAAXAqpg+X0R+gpQXh5mdClwGnAUcnurPF5GfLqXFYWYjgeXuPsDd1wMfmFnXVGYQkZ8uFcXR3MzOAZoBHwDFZtbNzGoDE4E6KcggIjtQKgZHT9rsa22C0+wvIziadFQKMojIDpT04nD3uVuY/SkwKbHWkZ/sDCKyY8V6zVF3/4HgjFkRySC6PYKIRKbiEJHIVBwiEpmKQ0QiU3GISGQqDhGJTMUhIpGpOEQkMhWHiESm4hCRyFQcIhKZikNEIlNxiEhkKg4RiUzFISKRqThEJDIVh4hEpuIQkchivXRgFFPbd487Qlq77rtP446Q9orzs+OOsNPQGoeIRKbiEJHIVBwiEtlWxzjM7CVga3eSN8DdvVdSUolIWqtpcLRvylKISEbZanG4+9dVj80sFzgXaOruN5tZE0BD1CK7qLBjHI8Q3KrxxMS0J+aJyC4obHE0cfd7gI0A7r4cyEtaKhFJa2GLY4OZNSIxWGpmnYBaSUslImkt7JGj/YBxQGcze49gs+X8pKUSkbQWqjjcfR7wazOrC2S5+5rkxhKRdBaqOMysIXA98HNgvZlNBu5y943JDCci6SnsGMcTwCzgGOBMggPAxiUrlIikt7DFUeDuj7n7endf4e5DgZ8lM5iIpK+wxfGZme1RNZE4AGxBciKJSLoLe65KLjDLzKYDZUB34OPkxxORdKRzVUQkslDnqgCY2Z5AM4KB0So/eo2I7BrC7o4dSzAY2h54DTgc+AR4K2nJRCRthR0c7ejuxwFvAAOBA9C5KiK7rLDFUWlmWQQDor8AfgB2T1oqEUlrYYvjRqAN8ChwOTAHeDZZoUQkvYU9V2Vytckjk5RFRDJETcdxjGLr1xwFwN377fBEIpL2alrjmJCyFCKSUWo6jmNaKoOISObQfVVEJDIVh4hEVtPg6BXbWtjdR+zYOCKSCWpa4/iu2p8OwKHAaoKDv44HGiU9nYikpZoGRx+temxmZwHHuXvVVc4fAF5Ifrz0k1u3DvlFhaxduCTuKLITWbZsGQUFtalXrzDuKKGEvcp5IYn7xSamK4CmSUmUpvKKCjl69C20OHB/Zt71ILNGPURWTg5Hj76Zei2bk5WbyxtXDmbF7M/jjhqbc07rReMmzQDYc++9uaRfsLW7YP48+vQ+mzvG3E/7DvvEGTF2p5x8Ek2bBj86HTrsQ8/jjmXk8BF88cW/uHfsOPbp2DHmhOGELY6HgUlmNh4oB/4HeDVpqdJQZXkFf791FI0770PthsUA7HXaiaxduIRJF19Dk/06cuC1fXn5N7vuZUzy8vIZPubHl6J1dx4YM4r9unWPKVV6ycvLY9wDD26aXrx4ETffditj7rknxlTRhdqr4u7jgD4EZ8Q2BG5094HJDJZuytaVsOLTf/14Xsl6cuvWASC/QRElS7+NI1pam/jcBA45rAf1CjNjFTzVWrTYjSZNMm/lPVRxJG46fRhQnNiT8pWZNU9qsgww96XgFJ5ez4xl/769eW/InTEnile9wkIuu+h8ru9/OfP/PZcV337Lhx+8z7En9Yo7WtqoX1if8887lz9e1o+5c7+KO852C7up8gjwPsFNp2/mPzedPjbsB5lZjruXbzavp7tPCvse6abhPnuRX1TIm1fdSJff/YY9Tu7JZ4//b9yxYjPi3gcA+Pyfn3LroD/RqnUbftenH2a2jSV3Hfc/9BAAn346m4EDrmP800/HnGj7pPKm01sqiGtrWsDMLjKzGWY2473SVRE/Lvm6X/V7pg+7lzXzF/L2wNvZv+95cUdKC3t33JfvVizni8/nMObOOxhweV9mTf87Y0YMY8mihXHHSwv77tuJ3NwcNmzYEHeU7RJ2jWNH3HR6NzO7AygBXnP397e1QGJsZRzAXYXtazxTNw4VZWUU79GaVV/Np6BRA6hMu4gpU1paSmVlBfn5tVm88BuaNGvOmIcf3/T87TcO4pTTzqD5bi1jTBmv0tJSKisqyK9dm4XffIM75Ofnxx1ru2zPTaffBWoDF0T8rMXu3t/M8oDjzWw40C7ie8Qmr7g+Jz0+ioKmjcnKzaHNcYcz+dLrOGbMLXTtdwG480b/IXHHjM36khIGXN6H2gV1yMnJ4crr/hx3pLRTsm4dfftcSp3E9+j6QYP4cPp07h83lq/nz+err76iSZOmjBg5Mu6o22SJY7pqfpFZPXdfW/2m01XzQixrwK+BPu5+5GbPveHuR4QJmo5rHOnkV/Nnxh0h7RXnZ8cdIe3VK6gdakAq7BjHCwDuvq7aneq3eRxHojSGAVs7zFJlIJKBatxUMbNLCc5L6WRmL1Z7qhD4fltvnjhEvX/ivare8zCCyw/mElzHVEQyzLbGOP4CvAKMB/5Qbf4Gd18W8bNaJcY1XnH3wQBm9ouI7yEiaaDG4kiMYaw1s/7AUnffCGBmdczsAHePsmE9392v/AlZRSRNhB3jGF5VGgDuXgIMj/JB7n70FmYPivIeIpIewu6O3biFeaGP4zCze4CqQVUD6rl7X3fXLSRFMlDY4phkZvcBIwjOjr0YmBXhc/apvivWzKZGWFZE0kzYGzLdbGZnAoMJDv6aCoxJZjARSV9h1zhw9/EEe1ciMbNjgQZm1rNqVvXpTD7JTWRXVdPFiodX7QUxs9n8+GAtIzhMo3OIz9iQWHZDYjm2MC0iGaSmNY6rqx64e6ft/QB3n2Zm31cfCN18WkQyS03F0WVb11Fw97ADpJu/kdY0RDJYTcVR/UjRJkBH4C2C63D0AN4Azgz5ObPN7JbEYwNmR8wpImmkptsj9K56bGbPA52rTnAzs6ZA6Ovk6a72IjuXsEeOFlU7K5bEeSqtkhNJRNJd2N2xn5rZTQS3SSgHfgPokt4iu6iwaxyXAV8DtwKjEvPOSUoiEUl7YY8crTCzN4F/u/uU5EYSkXQX9r4q1wC3EFzNCzPrZGaPJTOYiKSvsJsqJ7j7fxPcrR53n40GR0V2WWGLoyxx/dCq2yMUElw+UER2QWGL43ZgAsHl/24G3iHihXxEZOcRdnfs28CHwC+AbOAed9/alctFZCcXtjimuXt3YGIyw4hIZgi7qfK8mV1gZrubWYOqP0lNJiJpK+waxzGJr2dXm+cE90cRkV1M2APAQt2mUUR2DaGKw8waAwOBbsB6YDJwV/VbJojIriPsGMfjwEyCTZYzCa6pcV+yQolIegtbHAXu/pi7r3f3Fe4+FN33VWSXFbY45pjZHlUTiQv5LExOJBFJd2H3qrQCZprZh0AZ0J3gcoAv8p8rnvdKUkYRSTNhi+PipKYIYUVpedwR0lrZ4AvjjpD2Gr5VEHeEtFf60UOhXhd2d+zXPymNiOxUwo5xiIhsouIQkchUHCISmYpDRCJTcYhIZCoOEYlMxSEikak4RCQyFYeIRKbiEJHIVBwiEpmKQ0QiU3GISGQqDhGJTMUhIpGpOEQkMhWHiESm4hCRyFQcIhKZikNEIlNxiEhkKg4RiUzFISKRqThEJDIVh4hEpuIQkchUHCISmYpDRCJTcYhIZCqOiGrVrUP93ZvHHUMkVjlxB8gU+UWF/GrsUFod1JV37ryfd0c+AECLrp04ccSf8cpKFrw3k0kDb485aTwstxZNe19OVq08yM5hxTMPUrp4AQ1/eTb5bffGy8tZPn4sZcuXxB01Nped3ZNfHXUAtXJzGPXEZMa/+gFd92nNyGvOoqLCef/jL7nu7glxxwxFxRFSZXkFb9x0F83360hBw2IAsnNz6TXqRsafeSmrFyyOOWG8vKKcZQ/fiZeVkd9ub4qO6sXa6dPIyqvNohEDqdWyDQ1/fQ5Lxw6NO2osWjYtptcR+3N471vJz8tl5lODmTD5Q0b/6RzO6D+aBUu+iztiJCnZVDGzzptNH5+Kz92RSteVsHT25z+a16HXMcx5cdIuXxoAVFbiZWUA5DbZjY0L51OnUzfWfvgWAKUL55Fb3AjM4kwZm9KyCmrl5JCVZdSpncfK1SWcckRXXpg6K+NKA1I3xjESwMyeM7O2wCAz28vMMnqwoFnnDmTXyuXciY/Q+29P0OrgA+KOFKuiI0+i1cCR1Ot2KGvenUxOUUPKv1+x6fmKtavJKqgbY8L4fLtyDaOenMzr91/DsyP7celNj9J5r92plZvNy2OuYNK4qzi4yx5xxwwt1ZsqRcB+QCHwc6C/mR3g7pUpzrFDFDQsxisreezk3hS2bMa5Lz3C3fsdG3es2KyaOpFVUydSp8uBNPltHyw7B6/8zz+tu4N7jAnjU7cgn1OO6MoVtz9Jl71bcfHpR2AYle6c1OdOWjYt5uXRV9D51IFxRw0l6WscZnYD0MbMbgTc3Z8FlgFPAW9QQ3mZ2UVmNsPMZsyqWJPsqJGVrFjJl3+bhruz+pslrFnyLQWNGsQdK3Yl//g7tRo3p3ztKnLqF2+an11Qh8r162JMFp+zTjyIqdPn8PG/FvDoC+9QXK8ODYvq8rd3Z+PufLN0JYuXr6JRcb24o4aS9OJw9xuAee5+/WZP/dbdr3D30hqWHefu3dy9W9fswqTm3B5zp7zDXiccCQR7XfLrF7J+xcqYU8Uju6ghlpMLQK3dWlO2Yhnr5/yDut0OC+a1bEPpt7vuHpXSsgr2/FlTALKyjJbNGjD6r69zwmFdACiqV0BRvQJWfL82zpihpWpTpWpE7Jtq02+k6LN3iNrF9TnzqTHUbdqY7Nwc2p9wBM9edA0ly7/jgtfHA/BK/yExp4xPbnFDGl3Yn8oN66n8YT3Ln3mIijXfU3vPfdjt8iF4eTnfPjEm7pixeWLiezww+HzefvRPlFdU8uTL7/P2zC84+sCOTHnwGgCuGDY+5pThmadgm9PMGgEHuftEM/s98LS7RxpKvj6/3a65cRzSeRf/PO4Iaa/DWwVxR0h7pR89FGq3V9LXOMzs1sTDLmZ2CNAN2NfM1gAF7n5ZsjOIyI6V9OJw9wEAZnaxu481s2bANe4+wMxeTfbni8iOl6oDwHoCLwC4+1Lg4cTj481s1z74QSQDpeoAsGvdfalZcNigu38CkDgA7KAUZRCRHSTVZ8dONbPbzazq8MEjybC9KyISz2n1w4DbzKwI6Orun8WQQUR+glQcOXos0CAxzlHs7suB64DRwOc1LiwiaSkVaxzrgAqgJPEVIB+olfgjIhkmFYecvwusTnxdY2btgJuB3sA+Zpad7AwismPFMcbRG+jr7uuAScAhMWQQkZ8gVcVRdRjrCHcf6O4bE9PvEexZEZEMkqriGATg7i9Vn5kYKH0mRRlEZAdJSXG4+1s1PKfdsSIZRrdHEJHIVBwiEpmKQ0QiU3GISGQqDhGJTMUhIpGpOEQkMhWHiESm4hCRyFQcIhKZikNEIlNxiEhkKg4RiUzFISKRqThEJDIVh4hEpuIQkchUHCISmYpDRCIzd487Q0Yys4vcfVzcOdKZvkc1y+Tvj9Y4tt9FcQfIAPoe1Sxjvz8qDhGJTMUhIpGpOLZfRm6bppi+RzXL2O+PBkdFJDKtcYhIZCoOSQkz0/+1nYj+MeUnM7PDzey4bbxsmJllpySQJJ3GOLbCzPYAJgJLt/KSPkBz4FDgA2AV0Nrd/2pmRcCF7n5HSsLGwMxGAZ0Sk0UEv4RWJqY/c/dLN3v9L4Dm7j4hdSnTh5kdCtR199e28Nxt7n5ttenB7j4opQEjyok7QJq7zd0f2dqTZvbzapOtge/NrCVQCNQ3swJ3X5/ciLEpcffDIVjjAPKrfijM7LbE1ykE35dvqhYys75AC2Ax0NPdS1OaOkXMrAcwuNqs+kC2mV1bbd5t1b5njYFnEvPbJJYHuNzdP0564IhUHDW71szO28L8mcAI4GKgIXAiUAcYT/BbOB/YD2gD/DMlSdOQux9lZncCV3i1VVszG+HuV8QYLencfRpweNX0ltY4zKyFmV1C8H/l4GpFfJO7D0xt4mhUHDUbAhzk7v2qZphZE6AfwW/M04FzgKeAXwKPEPw2XQBscPddtjSqeQU4DHgLwMzygZJYE6WImfUCqgpy8zWOo9x9MXCfmbV29xfN7DGgVWLZN4HV7n5KqnOHoeLYutrAD8CzZnZatW3z3wMPAgVAD+Br4HbgWaAB0Jsfr6LurOok/nNDYoyj2g/FZ9Ve9zowiERxAMcD/287f2eUKIODgIfd/UvY9IvnanevSEw3Aw4wsz7ufk7VsmZ2KvCPOHKHoeLYuhbAInefbmZDzexdgsHQcnefB2Bm/wPUJdiOb0AwSDoJaBxP5NRx9z9UPd58jGOz17mZ5VabddjOvpmymSHAaDO7juAX0Q3AtQBm1oXgF81XwNNmNg2o2qRrCqxNDJS+nPLU26C9KlthZgOAu929xMzqAE8S/MP/puq3ReJ1OcAw4AmCAcM5u8Jeleq2VBybDQ62AeYlHrcD5iYe37alstnZmFk94GGgDOjj7is3e/42d7/WzNoCRwB/IdgMnuHun6c8cAgqji0wswKC1etbCQY+DwbeJFgl7wxMBj4B+hLshv0a+JxgFb0/cAzBD0Xa/aaQ1ElslhwC9ATmAKVAe+AjYAqwBHgV+HKzNbg7gSOBE9x9Uapzh6Hi2AIza0AwhtEWWO/uM6o9lw0cBSx3949iiihpzsw6Eqw1TAXec/eyzZ47EvjA3T/cwrL5BJvE5anKG5WKQ0Qi0yHnIhKZikNEIlNxiEhkKg4RiUzFIUljZjeY2Wk1PH+emfWP8H6RXi/Jo+IQABJHNoqEouKQKmfFHUAyh4pDMLMHCK4B8aaZ9UhsYowws2lmdrSZfVrttYeb2T2Jx43N7Gkzm2JmL5pZwxo+4yoze9vMZpnZBdWe2s3MXjCzv5vZfVWXGDSzYxPv+3bi8H9JIyoOwd0vBOa5++GJ60gANHX3Hu7+eg2LDgWud/ejgPv5zynkWzLR3Q8DfkFwWH6VHsBZ7n4gkAf8MnHk7sUEF/o5jODs0fbb97eTZNDZsbI1k0K85migrZlB8H+ppuuPlJvZ9cC+QMtq859396rrc0wguBRjGdAFmJJ47yIS16mQ9KDikK3Z2sV2qp8iv+nygTUxs0YEZw9fBtwJzKj2dPVLBxYA64Fs4Gl3/9EmylauxiYx0KaKbGJmtbby1NLEKd8QrBFUmWtmJySWrWtmbbayfGuCTaH3CdY22lZ77ngzy02MbZxHcOGf6cDJZlY/8d6dt+fvI8mjNQ6p8iQwI3Ex4c0NBh5KDJKWVZvfD3gwMXhZkZjeko+B/MTFkD4huHBNlS+A5wmu3fpcolwws6HAm2a2luBSjGdv999MdjidHSsikWlTRUQiU3GISGQqDhGJTMUhIpGpOEQkMhWHiESm4hCRyFQcIhKZikNEIvs/vJnYVFZRSosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "udn_preds = CountVectorizer_MultinomialNB(udn_train, udn_test['內容'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "udn_preds2 = list(udn_preds)\n",
    "udn_test['立場'] = udn_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "udn_test.to_csv(\"udn_naive_beyes.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3541666666666667\n",
      "Precision score: 0.3541666666666667\n",
      "Recall score: 0.3541666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAEOCAYAAAB4sfmlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF1RJREFUeJzt3XmcHGWdx/HPN5lJQshFQsjBFQ5lDZJwBJZDBIMGQRZRWF3ARVhZjgWJIre4XAaCXCp4RReQLB4RuWQBAxgCghwBAVmiHCJXGIgQkpCQY2Z++0d1xzabmfQD013VM9/365XXdFVXdf0oZr5d9dRTTykiMDNL0SvvAsys8Tg4zCyZg8PMkjk4zCyZg8PMkjk4zCyZg8PMkjk4zCyZg8PMkjXlXUC1jtEYd3HtxGe3HZF3CdYNfOT3D6qa5XzEYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJmvIuoBHtdMgn2evEI2lvbePXU7/HYzf+Ou+SiqVXL7b88gkM+If309R/XVpuvY2Xr/1Z3lUVRzfYPw6ORP0GDmDi5CO4aNcDaerbh5Pv/yVP3jqL1hUr8i6tMNS7N2/c9zueveSb0KsXE6Zfxeu3z2TFG2/mXVohdIf9U5dTFUn9JH2gHtuqtbF7f5jHb76T1hUrWLb4bZ677xHG7DQ+77IKJVauZMEDD2YT7e0snz+f3uuum29RBdId9k/NjzgkfQUYDIyXNBsQEKW350bEbbWuoSutt9Eo3nxx3qrpt15pYdDI4TlWVGx9hg2lacC6vPPiS3mXUkiNun/qcaryI2A0sLz0WsBwYD5wM9BQwdG7TzPR1rZqOtrbifb2HCsqrl79+vKBr5/N09+4NO9SCqmR90/NT1UiYiGwCHgH2BQ4C9iiNP/OztaVdJSkOZLmPMXiWpdalUUt8xk8esSq6SEbjmTByy05VlRMam5m66lTePHq/2bJ08/kXU7hNPr+qXlwSPoMMBZYB3gF+B7wjKStgIs7WzcipkXEhIiYMJaBtS61KnPvuJftD9qXXk1N9Bs0kI2325oXHn4877IKRb17M/brZzPvlzew4MGH8i6ncLrD/qnHqcoLwBjgYLKjjhbgSOAk4APAo3WoocssfPV17r9yBif/9jrUS9z01YuJiLWv2IOMOmB/hkzYnuah67HxYYcC8NQZZ7Fi/vycKyuG7rB/VOtfekmTyNo1ziULj4uA7YAbgEci4ifVfM4xGuO/zk58dtsRa1/IbC0+8vsHVc1y9bgcuwuwM9mVlc8C1wN/AU4ha/MwswZTj+D4LVlQvAlML81bEhFtwHp12L6ZdbF6BMe8iPgxcFBEvAzcEBH/VHrvCknuPWXWYOoRHN8p/fyypHPJ+nCUbbPatJk1gHreHTsBuBz4vKTTJQmYBNxVxxrMrAvU9Sa3iJgPnCtpO+Ba4M7wtUyzhpPXeByvAv2Bt3Lavpm9B3UPDkkHApOBQ4A96719M3vv6hockr4JzI+I0yNiKfCApO3rWYOZvXf1CI5Rkg4DRgIPAOtJmiBpHeAWoLEGIjCzujSO7rfaz3XIbrOfTNab9PI61GBmXajmwRERz61h9pPAzNJRR79a12BmXSvXMUcj4h2yO2bNrIH48QhmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJch06MMXkw8flXUKhrZwyPe8SrAfxEYeZJXNwmFkyB4eZJeuwjUPSr4COniQvICJi/5pUZWaF1lnj6PF1q8LMGkqHwRERL5RfS2oGPg+MiIgpkjYAetehPjMroGrbOK4me1TjJ0rTUZpnZj1QtcGxQURcASwHiIj5QN+aVWVmhVZtcCyTtD6lxlJJ2wB9alaVmRVatT1HTwCmAeMk3U922vJvNavKzAqtquCIiOeBT0saAPSKiEW1LcvMiqyq4JA0DPgasCOwVNIdwLciYnktizOzYqq2jeNa4FHgY8DBZB3AptWqKDMrtmqDo39EXBMRSyPirxFxIbBpLQszs+KqNjiekrRleaLUAezF2pRkZkVX7b0qzcCjkh4CVgI7AY/VvjwzKyLfq2Jmyaq6VwVA0vuAkWQNo2V/t4yZ9QzVXo79AVlj6FbA7cCewBPAPTWrzMwKq9rG0a0j4uPALOBMYAd8r4pZj1VtcLRL6kXWILob8A6wcc2qMrNCqzY4zgM2A34MfAmYC1xfq6LMrNiqvVfljorJiTWqxcwaRGf9OC6n4zFHAYiIE7q8IjMrvM6OOK6rWxVm1lA668cxu56FmFnj8HNVzCyZg8PMknXWOHri2laOiEu7thwzawSdHXG8UfHvA8CHgIVknb/2AdaveXVmVkidNY7+uPxa0iHAxyOiPMr5j4Cbal+emRVRtaOcD6L0vNjSdBswoiYVFZz69GHDY0+lV9++qKmZlmu+x/KX/5J3WYXz86um8b+PzaG1tZXPHXU8Y8dvn3dJhdLo+6fa4LgKmCnpp0Ar8C/AbTWrqsCitZVXvnshsXIF67x/a4bt+2nmTXNTT6UnHnmIv77ewrnfmsaihW9x/mlf4vzvXEmvXm6Lh+6xf6qqNCKmAceR3RE7DDgvIs6sZWGF1d5OrFwBQN9RG7HsxT/nXFDxPP/Mn/jgdhMAGDR4CEPXH85r817Ouari6A77p6rgKD10endgvdKVlGcljappZQU29OOfYoupP2DwLnuyYNbteZdTOJtuviUP3juLtrZWFi54k7888zSLFr6Vd1mF0R32T7WnKlcDvyN76PQU/vbQ6b2r3ZCkpohoXW3epIiYWe1nFMWbt9/Am7ffwMAJu7Lhv3+Zl6+4IO+SCmXbnXbh+Wf+xNlfPpaRG27MmC3fx6DBQ/IuqzC6w/6p50On1xQQp3W2gqSjJM2RNGfGn4o3SuHiOffTPGJ03mUU0qcOPZzzvv1Djjv1P1m0cCHDNuiRbekdavT9U8+HTm8o6WJJ50japZoVImJaREyIiAmf2aoYj3FpGro+amoGoO8mm7NyfkvOFRVPe3s77e3tAPzu7jsZs8X76NPHA8aVdYf9824eOn0fsA7whcRtzYuIkyT1BfaRdAmwReJn5K556HA2PuGrtC1dQvs7S2mZ/v28SyqcpUveZsopkwHYYNRojv7K6TlXVCzdYf+o1Ker84WkgRGxuPKh0+V5Vawr4NPAcRExcbX3ZkXER6opdO4R+6+90B5s5ZTpeZdg3cC40YO19qWqP1W5CSAi3q54Uv1a+3GUQuMi4NUOFnEYmDWgTk9VJP0H2X0p20i6ueKtQcCCtX14qYv6SaXPKn/m7mTDDzaTjWNqZg1mbW0c04FbgZ8CX6yYvywiXkvc1ialdo1bI+IcAEm7JX6GmRVAp8FRasNYLOkkoCUilgNIWlfSDhHxSMK2/hIRX3kPtZpZQVTbxnFJOTQAImIJcEnKhiLio2uYfVbKZ5hZMVR7OXb5GuZV3Y9D0hVAuVFVwMCIOD4i/AhJswZUbXDMlPR94FKyu2OPBh5N2M7Yykuxkn6TsK6ZFUy1D2SaIulg4Byyzl+/Ab5by8LMrLiqPeIgIn5KdnUliaS9gaGSJpVnVU434k1uZj1dZ4MVX1K+CiLpD/x9Zy2RddMYV8U2lpXWXVZajzVMm1kD6eyI45Tyi4jY5t1uICJmS1pQ2RC6+rSZNZbOgmN8ubdnRyKi2gbS1T/IRxpmDayz4KjsKboBsDVwD9k4HHsAs4CDq9zOHySdX3ot4A+JdZpZgXT2eIQjyq8l3QiMK9/gJmkEcFm1G/FT7c26l2p7jg6puCuW0n0qm9SmJDMrumovxz4p6etkj0loBQ4FXq9ZVWZWaNUecUwGXgAuAC4vzTusJhWZWeFV23O0TdLdwJ8j4q7almRmRVftc1VOBc4nG80LSdtIuqaWhZlZcVV7qrJvRPwz2dPqiYg/4MZRsx6r2uBYWRo/tPx4hEFkwweaWQ9UbXB8A7iObPi/KcBvSRzIx8y6j2ovx94LPAzsBvQGroiIjkYuN7NurtrgmB0ROwG31LIYM2sM1Z6q3CjpC5I2ljS0/K+mlZlZYVV7xPGx0s/PVcwLsuejmFkPU20HsKoe02hmPUNVwSFpOHAmMAFYCtwBfKvykQlm1nNU28bx38AjZKcsB5ONqeHHtJv1UNUGR/+IuCYilkbEXyPiQvzcV7Meq9rgmCtpy/JEaSCfl2tTkpkVXbVXVTYBHpH0MLAS2IlsOMCb+duI5/vXqEYzKxhFxNoXkjZd2zIR8UKXVNSBYzRm7YX2YFdu6yvja/PK7CvyLqHwhg/qX9VA4tVejq1pKJhZY6m2jcPMbBUHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh5klc3CYWTIHh3WpAf37sfHIoXmXYTXm4HgXdjrkk5w+51ec+sCNbHvA3nmXUwhDBvbnF5ccz9ybL+Cgj+0IwKajhvHqrG9zxw9P4Y4fnsKhn9gl5yqL42fXTufYLxzOkYcdyszbbs27nGRNeRfQaPoNHMDEyUdw0a4H0tS3Dyff/0uevHUWrStW5F1arlrb2jnvBzcxfqtNWH/IgFXzH3jiOT41+Vs5VlY8r7W0cO/sWXz3R1exYvlyPn/oZ5m0z755l5WkLkccksatNr1PPbZbC2P3/jCP33wnrStWsGzx2zx33yOM2Wl83mXl7u2ly3ji6ZfyLqMhNDc3s3JlK+3t7byz7B0GDRqcd0nJ6nXE8U1goqQbgK8AZ0l6DlgcEa/WqYYusd5Go3jzxXmrpt96pYVBI4fnWFFxtba1s/lGw5l99RnM/fM8TrtsBm8tXpp3WbkbOmwYnzn4EL54zL/T3tbGKWecmXdJyerdxjEE2BYYBOwI3CqpodpZevdpJtraVk1HezvR3p5jRcX1yusLGH/gmexx+Pk88fRLTDnhoLxLKoSlS5Zwz6xZfOmkU9jvgE9xw3Uz8i4pWc3/aCWdDWwm6TwgIuJ64DXg58AsOjnqkXSUpDmS5jzF4lqXWpVFLfMZPHrEqukhG45kwcstOVbUGK6+8V7GvX/jvMsohF/f9j/ssONOvH+rf2C//Q9g8aLF/PnZZ/MuK0nNgyMizgaej4ivrfbWv0bEiRHRYatiREyLiAkRMWEsA2taZ7Xm3nEv2x+0L72amug3aCAbb7c1Lzz8eN5lFdLgAeuser3fHtvy2J9ezLGa4mhubualF18AoK2tjddfa2Gd/v1zripNvdo4VPr5UsX0rDptu0stfPV17r9yBif/9jrUS9z01YuJiLzLyt16g9ZlxiXHMXLYYJqaerPvh8fz89sf5KiD9mTh2+/w+huLOP786XmXWQh777sf559zFkcdcRi9e/dm0j6fYNTo0XmXlUT1+KWXtD6wc0TcIulYYEZEvJHyGcdojP86O3HlthPzLqHwXpl9Rd4lFN7wQf219qXqcMQh6YLSy/GSdgUmAB+UtAjoHxGTa12DmXWtmgdHRJwOIOnoiPiBpJHAqRFxuqTbar19M+t69eoANgm4CSAiWoCrSq/3kbRDPWows65Trz4Up0VEiyQBRMQTAJJGATvXqQYz6yL17nz1G0nfkFS+mWEiDXp1xawny6PX5kXAVElDgO0j4qkcajCz96AePUf3BoaW2jnWi4j5wBnAd4A/1nr7Ztb16nHE8TbQBiwp/QToB/Qp/TOzBlOPLuf3AQtLPxdJ2gKYAhwBjJXUu9Y1mFnXyqON4wjg+Ih4G5gJ7JpDDWb2HtQrOMrdWC+NiDMjYnlp+n6yKytm1kDqFRxnAUTErypnlhpKf1GnGsysi9QlOCLink7e8+VYswbTUKNvmVkxODjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySOTjMLJmDw8ySKSLyrqEhSToqIqblXUeReR91rpH3j4843r2j8i6gAXgfda5h94+Dw8ySOTjMLJmD491ryHPTOvM+6lzD7h83jppZMh9xmFkyB4fVhST/rnUj/p9p75mkPSV9fC2LXSSpd10KsppzG0cHJG0J3AK0dLDIccAo4EPAA8BbwJiI+JmkIcCREXFxXYrNgaTLgW1Kk0PIvoTeLE0/FRH/sdryuwGjIuK6+lVZHJI+BAyIiNvX8N7UiDitYvqciDirrgUmasq7gIKbGhFXd/SmpB0rJscACyRtBAwCBkvqHxFLa1tibpZExJ6QHXEA/cp/FJKmln7eRbZfXiqvJOl4YDQwD5gUESvqWnWdSNoDOKdi1mCgt6TTKuZNrdhnw4FflOZvVlof4EsR8VjNC07k4OjcaZIOX8P8R4BLgaOBYcAngHWBn5J9C/cDtgU2A/63LpUWUETsJeky4MSoOLSVdGlEnJhjaTUXEbOBPcvTazrikDRa0jFkvyu7VATx1yPizPpWnMbB0blzgZ0j4oTyDEkbACeQfWN+BjgM+DlwAHA12bfpi8CyiOixoVHhVmB34B4ASf2AJblWVCeS9gfKAbn6EcdeETEP+L6kMRFxs6RrgE1K694NLIyIT9a77mo4ODq2DvAOcL2kgyrOzY8F/gvoD+wBvAB8A7geGAocwd8fonZX65Z+uaHUxlHxR/FUxXJ3AmdRCg5gH+D/ned3R6Uw2Bm4KiKegVVfPKdERFtpeiSwg6TjIuKw8rqSDgQez6Puajg4OjYaeCUiHpJ0oaT7yBpDWyPieQBJ/wIMIDuPH0rWSDoTGJ5PyfUTEV8sv169jWO15UJSc8Ws3bv7acpqzgW+I+kMsi+is4HTACSNJ/uieRaYIWk2UD6lGwEsLjWU/k/dq14LX1XpgKTTgW9HxBJJ6wI/Ifsff2j526K0XBNwEXAtWYPh3J5wVaXSmoJjtcbBzYDnS6+3AJ4rvZ66prDpbiQNBK4CVgLHRcSbq70/NSJOk7Q58BFgOtlp8JyI+GPdC66Cg2MNJPUnO7y+gKzhcxfgbrJD8nHAHcATwPFkl2FfAP5Idoh+EvAxsj+Kwn1TWP2UTkt2BSYBc4EVwFbA74G7gFeB24BnVjuCuwyYCOwbEa/Uu+5qODjWQNJQsjaMzYGlETGn4r3ewF7A/Ij4fU4lWsFJ2prsqOE3wP0RsXK19yYCD0TEw2tYtx/ZKXFrvepN5eAws2Tucm5myRwcZpbMwWFmyRwcZpbMwWE1I+lsSQd18v7hkk5K+Lyk5a12HBwGQKlno1lVHBxWdkjeBVjjcHAYkn5ENgbE3ZL2KJ1iXCpptqSPSnqyYtk9JV1Rej1c0gxJd0m6WdKwTrZxsqR7JT0q6QsVb20o6SZJD0r6fnmIQUl7lz733lL3fysQB4cREUcCz0fEnqVxJABGRMQeEXFnJ6teCHwtIvYCfsjfbiFfk1siYndgN7Ju+WV7AIdExD8CfYEDSj13jyYb6Gd3srtHt3p3/3VWC7471joys4plPgpsLgmy36XOxh9plfQ14IPARhXzb4yI8vgc15ENxbgSGA/cVfrsIZTGqbBicHBYRzoabKfyFvlVwwd2RtL6ZHcPTwYuA+ZUvF05dGB/YCnQG5gREX93itLBaGyWA5+q2CqS+nTwVkvplm/IjgjKnpO0b2ndAZI262D9MWSnQr8jO9rYvOK9fSQ1l9o2Dicb+Och4J8kDS599rh3899jteMjDiv7CTCnNJjw6s4Briw1kq6smH8C8F+lxsu20vSaPAb0Kw2G9ATZwDVlTwM3ko3dekMpXJB0IXC3pMVkQzF+7l3/l1mX892xZpbMpypmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmlszBYWbJHBxmluz/AAcODcQOEHT5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bbc_preds = CountVectorizer_MultinomialNB(bbc_train, bbc_test['內容'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_preds2 = list(bbc_preds)\n",
    "bbc_test['立場'] = bbc_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_test.to_csv(\"bbc_naive_beyes.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(binary = False, decode_error = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 月\n",
      "科技     0.330511\n",
      "金融     0.308062\n",
      "陳茂波    0.255508\n",
      "內地     0.244236\n",
      "香港     0.225232\n",
      "市場     0.220341\n",
      "國際     0.176035\n",
      "大灣區    0.165256\n",
      "中心     0.165256\n",
      "港澳     0.146542\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "5 月\n",
      "修例     0.468580\n",
      "香港     0.219569\n",
      "邱騰華    0.214286\n",
      "解釋     0.214286\n",
      "投資     0.175718\n",
      "情況     0.142857\n",
      "美國     0.142857\n",
      "公眾     0.142857\n",
      "民主派    0.142857\n",
      "政府     0.127127\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "6 月\n",
      "六四      0.289912\n",
      "台灣      0.255073\n",
      "民運      0.225487\n",
      "六四事件    0.198927\n",
      "三十年     0.193275\n",
      "蔡英文     0.175456\n",
      "政治      0.163240\n",
      "中國      0.161663\n",
      "八九      0.161062\n",
      "民主      0.154366\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "7 月\n",
      "顧汝德    0.492435\n",
      "年輕人    0.158832\n",
      "政府     0.153755\n",
      "管治     0.140253\n",
      "大學     0.139932\n",
      "社會     0.136338\n",
      "青年     0.127653\n",
      "林鄭     0.119872\n",
      "專訪     0.115983\n",
      "香港     0.112393\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "8 月\n",
      "大陸      0.583150\n",
      "台灣      0.443529\n",
      "蔡英文     0.220490\n",
      "政策      0.168235\n",
      "惠台      0.141452\n",
      "經濟      0.135833\n",
      "農產品     0.134285\n",
      "政治      0.120125\n",
      "陸客      0.117877\n",
      "兩岸關係    0.081175\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "9 月\n",
      "太子     0.265721\n",
      "徐淑儀    0.222892\n",
      "警方     0.201065\n",
      "列車     0.189268\n",
      "汽油彈    0.177972\n",
      "被捕     0.166095\n",
      "旺角     0.153959\n",
      "總區     0.150915\n",
      "將傷者    0.137736\n",
      "月台     0.134627\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "10 月\n",
      "社會     0.260779\n",
      "困局     0.192243\n",
      "張建宗    0.187668\n",
      "解決     0.177002\n",
      "機遇     0.164064\n",
      "方法     0.140898\n",
      "香港     0.139212\n",
      "秩序     0.136036\n",
      "國慶     0.135613\n",
      "當前     0.117662\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "11 月\n",
      "警方    0.354769\n",
      "進入    0.298312\n",
      "大堂    0.216560\n",
      "拘捕    0.209667\n",
      "暴徒    0.173724\n",
      "逃走    0.153173\n",
      "被捕    0.143882\n",
      "大廈    0.140139\n",
      "生閣    0.131823\n",
      "跪下    0.131823\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,12):\n",
    "    tfidf = vectorizer.fit_transform(hk[\"jieba_sentence\"][(hk['日期'] <= pd.datetime(2019,i,30)) & (hk['日期'] >= pd.datetime(2019,i,1))]).toarray()\n",
    "    tfidf_name = vectorizer.get_feature_names()\n",
    "    tfidf_df = pd.DataFrame(tfidf,columns = tfidf_name)\n",
    "    print(i,'月')\n",
    "    print(tfidf_df.iloc[0,:][tfidf_df.iloc[0,:]>0].sort_values(ascending = False).head(10))\n",
    "    print('---------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 月\n",
      "中國      0.220794\n",
      "普京      0.201049\n",
      "舉行      0.201049\n",
      "肖揚      0.201049\n",
      "海上      0.201049\n",
      "一帶一路    0.201049\n",
      "論壇      0.168495\n",
      "朝鮮      0.150787\n",
      "前院      0.150787\n",
      "領導人     0.150787\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "5 月\n",
      "談判     0.504219\n",
      "貿易     0.277625\n",
      "特朗普    0.239414\n",
      "股市     0.208219\n",
      "團隊     0.208219\n",
      "市場     0.191273\n",
      "中國     0.176748\n",
      "美國     0.169850\n",
      "中方     0.149634\n",
      "關稅     0.138813\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "6 月\n",
      "許穎婷    0.399414\n",
      "香港     0.321650\n",
      "內地     0.319893\n",
      "宏基     0.211455\n",
      "學生     0.203503\n",
      "同學     0.180371\n",
      "中國     0.178713\n",
      "文章     0.176362\n",
      "認同     0.162334\n",
      "身份     0.130824\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "7 月\n",
      "元朗      0.431086\n",
      "居民      0.380370\n",
      "新界      0.236767\n",
      "香港      0.207381\n",
      "港英政府    0.136807\n",
      "丁屋      0.113573\n",
      "基本法     0.106248\n",
      "鄉村      0.102605\n",
      "房屋      0.094823\n",
      "建制派     0.081249\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "8 月\n",
      "新加坡     0.613327\n",
      "香港      0.260876\n",
      "本土意識    0.160950\n",
      "管治      0.137157\n",
      "鄺健銘     0.128760\n",
      "對象      0.128760\n",
      "莊嘉穎     0.128760\n",
      "統治      0.117625\n",
      "政治      0.099559\n",
      "選舉      0.096699\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "9 月\n",
      "港交所    0.487988\n",
      "交易     0.350491\n",
      "倫敦     0.310839\n",
      "交易所    0.283968\n",
      "倫交所    0.209138\n",
      "李小加    0.174282\n",
      "英國     0.149526\n",
      "證交所    0.139425\n",
      "集團     0.112995\n",
      "便士     0.104569\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "10 月\n",
      "顏色革命    0.395663\n",
      "革命      0.219813\n",
      "變革      0.219813\n",
      "香港      0.192106\n",
      "中國      0.185975\n",
      "西方      0.171939\n",
      "顛覆      0.145633\n",
      "抗議      0.137706\n",
      "1989    0.137551\n",
      "發生      0.136917\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "11 月\n",
      "美國           0.295445\n",
      "香港           0.255775\n",
      "選舉           0.244808\n",
      "香港人權與民主法案    0.239384\n",
      "法案           0.174655\n",
      "區議會          0.131969\n",
      "美國國會         0.124527\n",
      "文章           0.124527\n",
      "私利           0.120583\n",
      "楊潔篪          0.120583\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,12):\n",
    "    tfidf = vectorizer.fit_transform(bbc[\"jieba_sentence\"][(bbc['日期'] <= pd.datetime(2019,i,30)) & (bbc['日期'] >= pd.datetime(2019,i,1))]).toarray()\n",
    "    tfidf_name = vectorizer.get_feature_names()\n",
    "    tfidf_df = pd.DataFrame(tfidf,columns = tfidf_name)\n",
    "    print(i,'月')\n",
    "    print(tfidf_df.iloc[0,:][tfidf_df.iloc[0,:]>0].sort_values(ascending = False).head(10))\n",
    "    print('---------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 月\n",
      "進會      0.259019\n",
      "台方      0.247249\n",
      "會和策     0.194264\n",
      "女友      0.177923\n",
      "陳同佳     0.172492\n",
      "協進      0.170352\n",
      "兩會      0.161817\n",
      "交流      0.154601\n",
      "林鄭月娥    0.154536\n",
      "回信      0.142163\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "5 月\n",
      "動議     0.341965\n",
      "林太     0.216321\n",
      "信任     0.196075\n",
      "票反     0.167288\n",
      "該動議    0.167288\n",
      "組別     0.167288\n",
      "贊成票    0.167288\n",
      "否決     0.153791\n",
      "上任     0.153791\n",
      "尹兆堅    0.144214\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "6 月\n",
      "韓特        0.333126\n",
      "英國        0.263669\n",
      "更顯        0.243283\n",
      "不移        0.231344\n",
      "抗爭        0.230016\n",
      "密切        0.222084\n",
      "紀念        0.208121\n",
      "移交        0.192335\n",
      "中英聯合聲明    0.189364\n",
      "承諾        0.173815\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "7 月\n",
      "巴士     0.548837\n",
      "調景嶺    0.329851\n",
      "免費     0.274876\n",
      "穿梭     0.236253\n",
      "等候     0.143959\n",
      "港鐵     0.141420\n",
      "堵塞     0.139296\n",
      "乘客     0.130059\n",
      "人龍     0.123928\n",
      "大塞車    0.118127\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "8 月\n",
      "未經      0.356222\n",
      "集結      0.274058\n",
      "批准      0.274058\n",
      "浩天      0.210483\n",
      "香港眾志    0.190657\n",
      "黃之鋒     0.185050\n",
      "相繼      0.176955\n",
      "明知      0.170429\n",
      "武器      0.165545\n",
      "煽惑      0.165098\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "9 月\n",
      "港澳辦    0.496286\n",
      "主任     0.328493\n",
      "張曉明    0.301675\n",
      "中聯辦    0.201311\n",
      "中共     0.196507\n",
      "招待     0.160674\n",
      "國務院    0.159224\n",
      "國安辦    0.135521\n",
      "下屬     0.124455\n",
      "協調     0.120505\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "10 月\n",
      "武警     0.430814\n",
      "灣體育    0.375421\n",
      "美聯社    0.313882\n",
      "深圳     0.253245\n",
      "模擬     0.250281\n",
      "演習     0.250281\n",
      "卅日     0.234849\n",
      "一組     0.234849\n",
      "中心     0.190525\n",
      "當天     0.166654\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n",
      "11 月\n",
      "催淚     0.337783\n",
      "吸入     0.270021\n",
      "健康     0.251589\n",
      "焚燒     0.216440\n",
      "評估     0.168891\n",
      "運動     0.165583\n",
      "探討應    0.150765\n",
      "肇始     0.150765\n",
      "一萬枚    0.150765\n",
      "及衛     0.150765\n",
      "Name: 0, dtype: float64\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,12):\n",
    "    tfidf = vectorizer.fit_transform(udn[\"jieba_sentence\"][(udn['日期'] <= pd.datetime(2019,i,30)) & (udn['日期'] >= pd.datetime(2019,i,1))]).toarray()\n",
    "    tfidf_name = vectorizer.get_feature_names()\n",
    "    tfidf_df = pd.DataFrame(tfidf,columns = tfidf_name)\n",
    "    print(i,'月')\n",
    "    print(tfidf_df.iloc[0,:][tfidf_df.iloc[0,:]>0].sort_values(ascending = False).head(10))\n",
    "    print('---------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
